Gracias, no más, me había pasado. Ahí vamos grabando. Entonces, retomando el tema del juego de buffers de TCP, el lado A quiere transferir, pongámosle entonces varios megabytes de datos, imaginemos muchos megabytes suficientes como para mantener totalmente lleno todo el canal desde A hasta B, ese canal virtual que se establece entre lo que vendrían a ser estos dos sockets, entre este y este. Entonces estábamos hablando recién que si estos son los, acá yo he dibujado sockets de transmisión en verde, perdón, buffers de transmisión en verde corresponden a los mismos sockets, cada socket tiene dos buffers, uno de transmisión y uno de recepción, el rojo el de recepción. Entonces el lado transmisor permanentemente va a recibir un feedback de cuánto espacio de buffer hay libre del otro lado del receptor. Y ese número, 32K habíamos puesto como ejemplo, para hacer el permiso de bytes que tiene el lado transmisor para tener bytes en vuelo a través de la red. ¿Por qué? Porque si yo inicio una conexión, hago el intercambio y leo, "Ah, el otro me publicó 32K", quiere decir que yo tengo el permiso de enviar 32K. Esos 32K no van a llegar instantáneamente, o sí. Si yo envío, ¿Llegan? No, tienen que pasar por los routers. Claro, tienen que pasar por todos estos links, routearse acá, tener suerte de que lleguen. Pero tengan presente que, qué sé yo, el otro día probamos cuántos milisegundos teníamos contra los POPs de Miami, de la costa este de Estados Unidos, y tenemos 100 milisegundos, 120 milisegundos. Obviamente tenemos un bufferío interesante, obviamente dependiendo de la distancia en hops y en, en definitiva, en distancia geográfica también, que hay entre las dos puntas. La red me está haciendo de un gran buffer. Pero los transmisores tienen que agarrar de algo para arrancar. Arrancamos y no puedo decir, "Ah, bueno, te envío". Si la aplicación, la bestia de la aplicación, me acaba de escribir un mega, me acaba de hacer un write al descriptor de socket de un mega, y yo no puedo, como TCP transmisor, decir, "Bueno, lo recorto, voy a redondear ahora en mil". Sabemos que el MTU en realidad es 1,500, menos cabeceras. Lo que yo voy a ahora hablar como un K es en realidad literalmente 1,460 típicamente. Entonces, volvamos. La aplicación me hizo un write de un mega, lo corto en mil pedacitos, en mil rebanados, en mil segmentos de un K, y los tiro así a lo bestia, martillazos, salen mil segmentos de un K desde A hasta B. Mal. Tengo que respetar lo que me dijo B como buffer de recepción. Si me inicio una conexión, y durante toda la conexión, como les decía, lo voy a estar leyendo, pero en el inicio yo reí 32K, y la bestia de la aplicación me escribió un mega, y bueno, recortaré de ese mega que me escribe la aplicación, tomaré los primeros 32K, lo corto en 32 pedacitos de un K, y los voy enviando uno atrás del otro. ¿Y cómo sigue evolucionando esto? Imaginemos ese escenario. La aplicación escribió un mega, el buffer mide solo 32K, todos estos buffers que vemos acá miden 32K, esto estaba vacío antes, yo soy el TCP del lado A, del lado transmisor. ¿Qué ocurre ahora entonces? ¿Qué ocurrirá? Primero se llena este buffer. Tenemos una situación de buffer de transmisión lleno, porque sencillamente, acá el sistema operativo que tiene este socket asociado acá, tiene este buffer de transmisión lleno, y con este buffer de trabajo, que de alguna manera es despertamos a TCP, un hilito ahí en el kernel, o algo en el kernel, que dice TCP, tenés laburo. Tenés este buffer de 32K, tu misión como TCP, es hacer que esos 32K lleguen obviamente al lado RX de B. Entonces, ¿qué hace TCP con esos 32K? ¿Cómo sigue esto? Aunque repite lo mismo que lo que... Lo envía. Nuevamente adaptándose al tamaño de la tagrama. Estamos redondeando en un K, hablamos que no es el número típico, pero lo recorta, por ejemplo, en pedacitos de un K, y los va enviando. Y después, ¿cómo avanzamos? Ok. Resolví los primeros 32K, pero tengo un Mega menos 32K hacia adelante, papi. Yo como TCP de la transmisión del lado A. Tienes que volver a llenar el software de transmisión con otros 32K. Claro, pero ¿cómo lo vacío? ¿Cuál es la condición que me hace vaciar este buffer de recepción? Estamos tratando de ver cuáles son las condiciones que permiten que esto fluya. Fíjense que todo es una gran montaña rusa. Si quieren, de un lado a otro. De TX a RX. RX lo consume la aplicación. ¿Y cómo yo voy despejando el buffer TX? Porque esto no es elástico. Buffer de transmisión no es que se va adaptando y va así estirándose. Es fijito. Entonces, ¿cómo yo despejo espacio en ese buffer de transmisión para poder tener bytes frescos de la data de aplicación para poder ir encolándolos para que vayan saliendo? ¿Qué les parece? Y B tiene que confirmar que le llegó los 32K. Perfecto. Las confirmaciones de B, es decir, acá está claro. La condición sería, tenemos este buffer de transmisión lleno. Lo recortamos en 32 pedacitos de 1K. Ya vamos a ver que eso es mentira, que no es así. No solo en tamaño, sino en la secuencialidad. Pero un detalle que ya lo vamos a ver. Van esos 32K. Y a medida que suben en RX acá, obviamente el TCP acaba haciendo el chequeo. Llegaron bien, llegó bien, llegó bien, llegó bien. Y va enviándole acá acusas de recibo. Y esos acusas de recibo son los que me permiten a mí ir, como hacer este desplazamiento del problema. Mi problema inicial era de acá a acá. Imaginemos que ese fuera un pedacito de 32K. A medida que yo voy recibiendo los acusas de recibo, este segmento se me va moviendo. Es como que, si ha habido un ACK a esta posición. Como consecuencia del ACK en esa posición, lo que va a ocurrir va a ser que esos 32K se me mueven acá. Y yo puedo morder este espacio de diferencia que estoy dibujando acá. Como que inicialmente yo tuve este permiso de 32K. Y se me va ampliando el permiso, no se me va ampliando, se me va moviendo el permiso a medida que se me van ACKeando lo que yo recibo. Fíjense que el ACK es ahí, acá no estoy en la escala, pero más o menos es como que lo que me alcanzó a ACKear a mí acá, es lo mismo que este segmentito de acá arriba, lo que me permite a mí avanzar. Acá estoy en el punto 1, se me ACKea y se me mueve a la derecha. Es decir, esto vendría a ser el punto 1, este es el punto 3. Y vamos a ponerlo acá. Este es el momento 2 con el ACK. ¿Se entiende más o menos? Yo estaba acá, se me ACKea, entonces si el otro lado me dice, "Che, loco, ya recibí los primeros 5K, ok". Yo ya puedo morder, que sería el segmentito de arriba, puedo mover esto y decir, "Ah, bueno, puedo olvidarme de estos 5K iniciales que estaban acá, despejar este espacio de buffer". Y ya liberé de estos 35K, liberé 5K porque el otro lado me dijo, "Ok". Con lo cual yo movería, esto no es así por una cuestión de optimización, pero lo podemos pensar conceptualmente. Muevo estos bytes que estaban acá esperando para salir hacia abajo, me despeja el espacio de buffer, muerdo más de la aplicación y pongo otros 5K acá. Entonces, de alguna manera la misión de TCP es ir avanzando. No quiero decir la ventana porque se puede confundir con el concepto de ventana de recepción, pero este segmentote de problema en el cual TCP dice, "Bueno, mi problema empieza acá, empieza acá". Y de alguna manera siempre hay, esto lo mencionamos, hay como varios punteros en juego, pero hay un puntero. Acá, por ejemplo, es donde empieza mi problema, el que estoy marcando acá, en el momento 3, esto sería para TCP. Acá empieza mi problema porque de acá hacia adelante tengo datos sin confirmar. Tengo en vuelo esto ya, que aún obviamente no ha sido confirmado, por eso estaba antes ahí, pero ya tengo despejado esto porque me acaban de confirmar el mismo espacio al comienzo. Entonces, yo me he podido mover, dado que el otro me está diciendo que tiene una ventana libre, me puedo mover y seguir empujándole datos. Entonces, siempre es un juego de TCP tratando de, el problema que le tira la aplicación, que es una secuencia de bytes, tratando de ir empujándola, en este caso, de izquierda a derecha. Aquí se complica porque en realidad ocurren dos cosas simultáneamente. Ocurre este flujo, al igual que este flujo. Todos los protocolos, no todos, generalmente los protocolos son bidireccionales. Entonces, acá hay como, si se quiere, dos instancias del problema de empuje de TCP, porque T, como habíamos mencionado en la clase pasada, no por nada es transmission control protocol. El problema de TCP es como empujo de data. ¿Se entiende más o menos esto? Era muy importante que lo visualizáramos. Va a quedar más claro a medida que lo vayamos viendo, pero ¿se entiende? Sí, seguro. Sí, va bien. Vamos a abrir una nueva antes de ir a las diapos. Porque me interesa que hablemos un poco de cómo es este famoso three-way handshake de TCP. Acá yo podría... ¿Cómo abría acá? Bien, perfecto. Entonces, voy a dibujar dos líneas verticales. Y acá estamos poniendo el foco entonces, en el inicio de la conexión. Acá está. Por una cuestión meramente de simplicidad, vamos a asumir que A inicia la conexión. Nuevamente, si lo vamos a un ejemplo concreto y vemos que acá hay mucho push ahí, esto sería un caso típico de que A inicia la conexión para empujar data, por ejemplo, un upload de medios. Lo que decía recién de imágenes a Instagram, por ejemplo. Bien. Entonces, a algunos de ustedes les debe sonar, o lo habrán visto, que el intercambio de TCP para iniciar una conexión es lo que se llama el three-way handshake. Discúlpenme, esto deberían ser... A ver, podría ser. Creo que si yo ponía ahí, y apretaba shift. ¿Alguien recuerda cómo hacer líneas? Hay una manera. Lo era con el shift, ¿no? Sí, ahí va, ahí va con el shift. Perfecto. Gracias. Vamos ahí. Vamos ahí. Un poquito menos. Fucking shit. Vamos ahí. Y eso sí, las flechitas se las voy a dibujar a manopla. Así. Así. Y así. Ya vamos a ver más detalles, pero vamos a ir al hueso. Este paquete se llama "SIN". Ya vamos a ver por qué se llama "SIN". Este paquete se llama... "SIN". "SIN". "SIN". "SIN". "SIN". Vamos a ver eso en realidad. Vamos a ver que son flags dentro de la cabecera TCP, pero básicamente el "SIN" es por... Viene del "sincronicemos secuencias". Lo que tenemos que hacer es sincronizar nuestros ceros de comienzo de conexión. No es como decir "sincronicémonos". Yo que inicio la conexión, mando un "SIN". El otro lado, ¿qué corresponderá a ese "SIN"? ¿Cuál es la respuesta al "SIN" que yo mando aquí? Desde "A" hacia "B". ¿Con qué me responde? ¿Cómo sé yo, como "A", que al otro le llegó el "SIN"? ¿Qué les parece? Veo que ahí me está volviendo otro "SIN". Bien. ¿Pero ese "SIN" en qué será? ¿Como respuesta a mi "SIN" o...? Recuerden, acá hay algo importante. Siempre se tienen que parar en que acá ustedes no somos dioses que vemos "A" y "B". O somos "A" o somos "B". No sabemos lo que... El único feedback de lo que está pasando en el otro lado son los paquetitos que me llegan. Yo soy "A", yo envío un "SIN". Y ahora me viene un "SIN ACK". ¿Qué les parece? ¿Cuál sería el significado de ese "ACK"? ¿Qué me está "ACKeando"? Yo no le envié... La sincronización del "SIN". Claro, me está "ACKeando" el hecho de haber recibido el "SIN". Quiere decir que este "ACK" en realidad corresponde a este "SIN". ¿Y qué me está diciendo el otro? ¿Por qué me dice "SIN"? Para el puerto. Para también sincronizar. No, los puertos ya van todos definidos en este momento. No hay un... Este primer paquete tiene toda la info de puertos en juego. No hay después un cambio de puertos acá. ¿Qué pasa? Este "SIN" con el "ACK" me permite abrir mi lado de transmisión. Pero yo no sé el otro. Recuerden, recuerden. Y esto es súper importante. Esto es súper recontra-bidireccional. Todos los lados hay que abrirlos ambos. Y después son igualitos frente a la ley. ¿Sí? Por lo tanto, yo en el primer "SIN" y con el "ACK" yo si se quiere es mi lado de transmisión. Pero le tengo que permitir al otro que abra su lado de transmisión. Por lo tanto, ¿qué será ese "SIN"? Justamente el otro diciéndome "OK, bien". Acá va mi inicio de conexión o mi sincronización. Entonces, obviamente, él abre su lado y yo... Acá yo le estoy "ACK"ando ese "SIN". Desde ese momento ya podemos transferir data. Ahora acá ocurren varias cosas súper interesantes. ¿Conocen el problema de los generales bizantinos? ¿Lo han visto en redes? No, no lo sé. ¿No? OK. No importa. ¿Cómo yo puedo estar absolutamente seguro de que B ha recibido este "ACK"? El tercer "ACK". Mejor dicho, el tercer mensaje. Porque pongámonos... A ver, a ver. Varias cosas primero. ¿Qué son estas líneas verticales? ¿En qué las mido estas líneas verticales? En tiempo. Excelente. Quiere decir que si yo acá tuviera que ponerle una unidad a esto, ahí, se lo pondría en segundos, milisegundos. Pero, ¿eso qué representa? Esto tiene un nombre en redes. ¿Le suena? Empieza con "R". "R". "Round". "Round trip time". RTT. Exactamente. Fíjense que es fundamentalmente igual a un "ping", si se quiere. Nada que ver el "ping" con lo que estamos estudiando ahora. Pero es lo que nosotros leemos con el "ping". Es a qué distancia está de ida y vuelta el otro lado. Yo no puedo saber la distancia de ida y la distancia de vuelta, a menos que el otro me ayude, me ponga timestamps y demás. Yo puedo saber cuánto tarda el boomerang en ir y volver. Entonces, ese es el RTT que yo estoy midiendo contra el otro lado. ¿Qué sería, por ejemplo... Muy bien esa respuesta, por cierto, de que esto es tiempo. ¿Qué sería ese tiempo? Este tiempo que yo a propósito le diría que una pequeñita distancia. Procesamiento. ¿Procesamiento por quién? Por el "A". ¿Qué cosa del "A"? ¿Cuál capa de "A"? Muy bien que es "A". Es tiempo porque está en "A", no que otra. Pero esto qué sería. Es tiempo... Si yo te tuviera que preguntar de cuál de las tres capas es la que más está llevando tiempo ahí. En realidad todas, obviamente, porque depende de yo a dónde medí que llegó el "A". El "A", lo medí acá, lo medí acá, acá. Pero como esto es "A", que es un concepto de capa de transporte, obviamente, IP no tiene la más mínima idea de qué son estos "in" y "ax". Estamos diciendo que acá acabamos de leer un "A" entrando acá. Entonces, yo lo estoy midiendo acá porque es cuando soy consciente que entró ese "A". Hasta que... Leo el "A" del otro lado. ¿Hasta qué le puedo yo decir mi "A"? Este tiempo, ¿por quién va a ser ocupado? ¿Quién está ahí tomándose ese tiempo y por qué no es cero? ¿Qué les parece? Ojo, ese tiempo es absolutamente equivalente, yo no lo he dibujado acá, a este tiempo. Está muy bien, que es el tiempo de procesamiento de algo en "A" y algo en "B". ¿Qué será? ¿De quién? Esa es mi pregunta en realidad. No es IP, no es enlace. Estamos demasiado arriba. Quedan dos posibilidades, transporte o aplicación. ¿Qué les parece? Transporte. La aplicación no es consciente del "sin" y el "ax". Muy bien, excelente. ¿La aplicación qué hace? Hace, como ustedes recuerdan, "socket", "connect" si es el lado cliente, "write", "write", "write". "Write" y "read", "write" y "read", "write" y "read". Pero nos dice, che, enviemos un "ax", che, llegó el "ax", enviemos un "sin", che, llegó bien ese "sin" "ax", ah, no, mirá, hay que retrasar, no, mirá. No, no, no, así, justamente la idea de, muy bien, que el transporte, justamente la capa de transporte que tiene rascarse la cabeza y resolver todo eso. Pero la aplicación tiene que quedar todo en una bandejita de plata, así, donde la aplicación haga "writes" de un lado, la otra puede hacer "read" del otro y listo. Entonces, efectivamente, un tiempo de procesamiento de TCP. ¿Y qué se les ocurre que está haciendo TCP? Se toma ese tiempo, hace un "time" y le dice, no, a este "boom" no lo vamos a hacer, tardó un poco, meternos 20 milisegundos y listo. Ya está. ¿Por qué no es cero? ¿Qué está haciendo ahí TCP? ¿Qué les parece? ¿Qué es lo que está haciendo TCP? Calculando si no llegó erróneo, por ejemplo. Por ejemplo, bien. Recuerden que, muy bien, muy bien, el chequeo de integridad de datos de TCP no va a ser solamente cuando transfiramos datos, sino que también tiene que proteger su propia integridad de cabecera y demás. Por lo tanto, ese procesamiento va a ser, bueno, yo levanté este segmento, bueno, la cabecera, le corro el checksum, veo que esté bien, veo que además, súper importante tengan presente que este paquete no entra ya directo al socket. Es decir, acá hay mucho procesamiento para decir, acá en TCP, acá está súper simplificado, entra este segmento, pero hay algo que dice, este socket estaba abierto, ¿alguien envió acá un SYN? ¿Esto está en curso? Para recién enchularlo y decirle, ah, sí, clack, esto corresponde a esta conexión que sí existe y no es un flaco que me está tratando de atacar mandándome SYN/AXE para SYN que nunca existieron. Y ahí es donde está todo el tema del estado, ¿no? Lo que habíamos hablado del estado. Acá hay un estado no conectado. Díctenme, ¿cómo pondrían con sus propias palabras los distintos estados? Yo ya les spoileé uno. Estado sin conexión. ¿Cuáles podrían ser los siguientes estados? Al mandar el SYN entra en conectando. Bien, perfecto, excelente. Y al recibir el AXE, conectado. Bien, y obviamente eso está 100% sincronizado de un lado del otro, ¿no? Al mismo momento de tiempo, prácticamente no existe el problema de la relatividad. Así, chk, están conectados. ¿O no? El Einstein, ¿no? Perdón, hagámoslo correcto. Esto es sin conexión hasta acá. Estado conectando sería precisamente, exactamente, en el momento en que está ocurriendo esto. En este momento ahí. Estado conectado, más o menos acá al medio, porque acá esto es tiempo de procesamiento TCP. Podríamos decir que, yo lo voy a dibujar más o menos acá al medio. ¿Cómo lo puedo dejar? Está mal diciendo. Acá ahí, pegadito ahí. Entonces, estado conectado. Estado. Junto. Estamos conectados. No hay nada más que dudar de nada. Ahí más o menos a la mitad. Bien, ¿qué pasa del lado B? Empieza sin conexión. Sin conexión, pero acá hay algo interesante que el lado B hace apertura pasiva. Sin conexión, pero esperando, ¿no? Porque, bueno, pasiva. Está esperando, está listo, o mejor dicho, listo para conectarse si se quiere. Si lo quisiera hacer un poco mejor. Bien, ¿cómo evolucionaría en estos estados? ¿Qué les parece? Cuando le llegue el SIN, entra en conectando. Muy bien. Y al recibir el ACK, conectado. Correcto. ¿Qué les quiero mostrar acá? La dura realidad. ¿Cuál es la dura realidad? Seguramente no es así. No, no, no, es así. Está muy bien, está muy bien. ¿Cuál será la dura realidad? Que el tiempo existe, ¿no? Y que la relatividad existe. No hay un tiempo absoluto, ¿no? Yo ahora, para nosotros, en nuestros ojos, es muy fácil jugar a ser Dios y decir "Ah, mirá, ah, sí, está conectado el otro todavía, no, yo lo veo y tengo una instantánea". Pero piensen nuevamente en la dificultad de que yo soy A o soy B y no tengo más feedback del otro lado de lo que ocurra y que venga con los distintos paquetes, ¿no? Yo tengo que figurarme, tratar de entender que el otro está o no está. Y ahí volvemos entonces a la pregunta. ¿Qué pasa si se pierde el primer SIN? Vamos a hacerlo más simple de todas. ¿Qué pasa si se pierde el primer SIN? ¿O no se puede perder el primer SIN? Sí, puede pasar. Es IP abajo, ¿sí? Yo armé, yo subí un TCP súper bonito, qué sé yo, le puse todos los firuletes, pero después abajo tengo una red que es BEST DEFAULT. Absolutamente puede pasar. Y más si estoy con el célulo con muy baja señal, una red Wi-Fi muy ruidosa o en el patio de casa muy lejos de mi AP. Sí, ese SIN, bien que se puede perder. Listo, se rompió la conexión, ya está, sonó. Listo, ya. Tengo que abrir una nueva conexión. ¿Qué podrá hacer TCP del lado A que está intentando iniciar una conexión hacia B? Y ese SIN se perdió. Esperaron, claro. Esperaron un tiempo y... Considerarlo, y acá hay algo interesante que vamos a empezar a ver. Considerar el SIN como si fuera el primer byte virtual. No es el primer byte, obviamente, pero pensarlo como un byte virtual. Y meterlo en la cabeza como que tengo que hacer el mismo esfuerzo de cuando yo estoy enviando datos. Entonces, bajo ese concepto, ¿el TCP qué va a hacer? Va a ser como si hubiera enviado este primer byte virtual y dice "envíe el SIN". Yo estoy esperando que me lo hagan ACK, igual que cualquier byte que enviaré luego. No me hicieron ACK, pasando el terminado tiempo, ACK timeout, reintento. SIN forzara a un error en la aplicación de decir "pucha, tu connect falló, dale fruta" y haces la aplicación con un violento "while connect" o "while not connect", así. No, TCP por debajo está haciendo toda la paquetización de esto, está haciendo todo el laburito. Cuando tiene éxito, alguna vez que cuando pase este SIN, intenta uno, timeout, intenta otro, quizás también se pierde por cuanto a timeout, reenvía otro SIN. Imaginemos que llegó a B, con lo cual acá yo tendría que dibujar, obviamente, distintas flechitas, ¿no? En donde la raíz de esas flechitas sería el ACK timeout. ¿Se entiende? Es decir, a ver, lo voy a dibujar, pero después lo voy a borrar para que no quede sucio el dibujo. Es como que TCP envió este SIN, además con la gravedad de que no tiene todavía un feedback de cuál es el RTT, porque no ha tenido, asumamos, que no ha tenido previo contacto, previa historia con el otro lado. Por lo tanto, TCP envía un SIN y dice "bueno, sí, pasó un rato y acá no me llegó nada". Acá está el segundo SIN. Lo que quería decirles es que esta distancia en tiempo vendría a ser el timeout que hizo TCP, llamado ACK timeout. ¿Por qué? Porque timeouteó el ACK, dijo "no, acá no hubo ACK, tengo que reenviar el SIN". Y es básicamente el mismo segmento, intentar reenviarlo, reenviarlo, reenviarlo, hasta que reciba el ACK. Entonces, cuando yo recibo el ACK, ahora sí, yo estoy contento. ¿Qué pasará ahora? Recordemos que estos dos son iguales ante la ley de TCP. B ahora está enviando su lado SIN. Logra ACK el segundo, y acá está el three-way handshake. Primero, segundo, tercero. El segundo, ok, llega hasta acá. ¿Qué pasa si ese segundo no llega? ¿Qué les parece? ¿Cuál es el segundo? ¿Cinco? Ajá, este es paquete uno, paquete dos y paquete tres. Le vamos a poner un numerito. Le vamos a hacer uno. ¿Qué pasará? Y se queda esperando el ACK, y como no llega, lo vuelve a mandar. Un timeout. ¿Y este lado cómo lo interpretará? Profe, disculpe, el SIN y el ACKC recibe el ACK. ¿Son dos paquetes distintos o no? No, son flags dentro del mismo, son flags a la cabecera, y lo vamos a ver. Es una optimización. Está muy bien tu pregunta, podrían serlo, pero como vamos a ver cómo esto es tan bidireccional, sería un despropósito mandar data. Pensemos al SIN como un byte virtual de vuelta, tratemos de meternos eso en la cabeza. Es como que yo enviaría, bueno, acá van los datos en este paquete que yo te empujo, y acá va otro paquete con el ACK al tuyo. No tiene mucho sentido y voy a gastarle el doble de PPS, packets per second, a la red. Más vale pongámonos todos uno solo, y la cabecera tiene tanto mi lado como la... tiene mi cara transmisora como mi cara receptor, la misma cabecera. En mi cara transmisora yo le digo lo que estoy empujando, SIN, espacio, secuencia que empujo, en mi cara receptora yo le voy a ir dando ACK a lo que él me ha estado enviando. Con ese mismo criterio, entonces eso es un solo paquete. Bien, entonces, ¿qué pasa si dos se pierde? Claro, porque ninguno de los dos recibiría un ACK recibo, entonces los dos como que volverían... Fíjense, ¿qué les quiero mostrar con esto? Hace falta que... lo que les quiero mostrar es la complejidad del problema. Uno piensa, primero, primera asumpción, que la red es perfecta. Horrible asumpción, y más aún ahora que somos tan wireless. Jamás podemos pensar en esa asumpción. Por lo tanto TCP tiene que hacer un montón de laburo. Fíjense lo complicado que es que se pierde el segundo, porque si se pierde el segundo, los dos lados están perdidos ahora. ¿Por qué? Porque para A, por más que llegó el SIN al otro lado, no le llegó el ACK. Entonces para A, en realidad es como si el primero se hubiera perdido. ¿Se entiende? Si se pierde el dos, para el lado A es lo mismo que si se hubiera perdido el uno, porque nunca le llegó el ACK. Entonces, ¿qué va a ocurrir ahora? Va a depender un poco los timings, de un lado y de otro, pero acá obviamente, ¿quién va a tener la misión de retransmitir, en principio, el paquete dos que tiene el SIN, el lado B, de reempujar ese SIN ACK? Pero a su vez el lado A, si se cansa, si se termina el timer, que se le va a terminar antes que el lado B, también va a reenviar el SIN. Entonces, bien puede ser que esa retransmisión de los dos, del uno y dos, se cruce en el camino, ¿no? Si es que yo lo pudiera fotografiar en algún punto, ahí, intermedio de la red. ¿Se entiende ese problema? Y la complejidad de ese problema es lo importante de entender, ¿no? Por suerte, el SIN, hacer un byte virtual, tiene garantía de empuje. Garantía de empuje es que quien lo puso, va a pelear por él. Quiere decir que, vamos a super simplificarlo, por este interlacing de timing que hay entre uno y el otro, pero el SIN que va en el uno, el lado A va a pelear por él, porque es el que sabe, yo tengo que mandar este SIN, byte virtual. Tengo que empujar al otro lado y lo voy a empujar hasta que me lo acknowledge. ¿Sí? Bien, perfecto. El lado dos, lo mismo va a hacer con su SIN, tengo que empujarlo hasta que me lo haga acknowledge. ¿Qué pasa si se pierde el tres? Nada, si ya va el uno y el dos, si se pierde el tres... ¿Alguien se va a enojar acá? Y el B se va a enojar. Se va a enojar, sí, claro. ¿Y qué va a hacer B ahí? Volver a enviar dos. Claro, volver a enviar dos. Ahora, fíjense lo interesante. Para el lado A, ¿cuál es la situación del universo para el momento en que envía el ACK? Ese tercer, el tercer mensaje con el ACK solito. ¿Cuál es su estado del universo? ¿Cuál es su visión del universo para A? Que se piense que está conectado. Por lo tanto, para A, si tengo data para enviar de A hacia B, démosle fruta, muchachos. ¿Cierto? Sí. Démosle fruta, ya está. Ya envié el ACK y acá tengo un mega... Y para el pobre B, todavía el guaso está tratando de recibir el ACK de su SIN y le está llegando todo un flujo de data. ¿Qué quiero destacar con esto? Lo complejo que es mantener un estado sincronizado entre dos cosas que están distantes en el tiempo. Porque en definitiva, acá la diferencia es el vertical que tenemos es tiempo. Entonces, para TCP es muy stateful y tiene que tener muchas cosas en consideración para tratar de mantener la coherencia entre esto. En esto, ¿no? ¿Cómo podré...? Y acá viene algo que quiero que nos saquemos de la cabeza. Va, mejor dicho, que lo aprendamos es... Fíjense que para ese tercer ACK, "Flaco, te envié el ACK, plim". Tu problema si no te llega. Porque no hay un ACK del ACK, porque si no después vendría un ACK del ACK del ACK, con lo cual voy a necesitar un ACK del ACK del ACK. Y ahí viene el problema de los generales bizantinos. ¿Cómo hacen...? Imagínense dos generales en dos cerros distintos, en dos lomas distintos, teniendo que atacar a alguien que está en el valle, al enemigo que está en el valle, y su única forma de comunicación es con mensajeros que pasan a través de este valle, con potencial pérdida. ¿Cómo hacen los dos para sincronizarse si no tienen otro medio de...? No tienen por decirte lucecitas ni nada, ¿no? ¿Cómo hacen para sincronizarse, para estar seguros de que los dos recibieron el mensaje de atacar a tal hora? La idea es asegurarse de que vamos a atacar a las dos de la tarde, son las once de la mañana. Esperar el round trip time. Claro, a ver, yo soy el general A, que le envío el mensajito al B, y tengo que esperar que venga un soldadito de B a decirme "A recibió bien tu mensaje". ¿Y cómo sabe B que A lo recibió bien? Con el último "ac". Mandó un tercer soldadito. ¿Y cómo sabe A que el tercer soldadito sobrevivió? No sabe. No lo sabe. Entonces le pido a B, le exijo a B que mande un cuarto soldadito. Sí, pero sería infinito. Sería infinito, a eso quería llegar. No hay manera, ¿sí? Acá tienen que haber timers, tienen que haber expectativas, y si no recibo, lado B. Si no recibo el tercer mensaje, entonces asumo ese periodo, tengo que retransmitirlo. Pero no hay una visión unificada del estado de ambas lados. Siempre va a haber un desfasaje. Eso es importante, importantísimo que lo tengamos presente, ¿no? ¿A qué fui con todo esto? A que no hay "ac" de los "acs". Porque no tiene sentido. Los "acs" solamente "ackean" a nueva data que había estado en vuelo. Y quien tiene que pelear por recibir esos "acs" es el lado transmisor. La receptor obviamente los envía, si los recibió bien, si los checks son "done ok". Pero es el lado transmisor el que tiene que empujar para que esos "acs" lleguen. ¿Sí? Eso es un concepto súper, súper importante. Y ahora vamos a volver a las diapos. Déjenme que las abra acá. Maldito tiempo relativo, ¿no? Qué lindo fue ese día, el tiempo fue el absoluto. Ok, nosotros entonces la clase pasada habíamos terminado de presentar acá y ahora vamos a entrar en un concepto súper importante que es el siguiente. Acá como bien habíamos hablado, TCP mantiene una ventana que es determinística, que es esto, ¿no? La ventana, lo que el TCP transmisor, es decir, "a", va a mantener en todo momento, va a ir recibiendo un feedback del lado B de cuánto es el buffer recepción del otro lado, lo que se llama la ventana de recepción. Esa ventana de recepción, como hemos hablado bastante ya, regula de alguna manera el ritmo indirectamente, la cantidad de data que yo puedo tener en vuelo, como lado transmisor, en base a la ventana de recepción. Hemos hablado en la clase pasada que esa ventana de recepción puede ser tan despejada como todo el buffer, generando una aplicación que es súper, súper, que tiene la posibilidad de despejar este buffer, de leerla, de consumir ese buffer lo más rápido posible, y tenerlo siempre súper despejado. Pero bien puede ser una situación, sencillamente que la aplicación, el próximo paso que tiene que hacer, el próximo procesamiento con eso que le envía "a", la aplicación del lado B, sencillamente no lee ese buffer y "b" tiene, perdón, "a" tiene más velocidad de transmisión de lo que "b" puede consumir eso. Entonces se va a presentar una situación de buffer lleno, situación de buffer lleno es una situación de ventana cero hacia el lado de "b" hacia "a", imaginando que "a" está tratando de enviar. Ese buffer es determinístico, porque yo lo leo, va en cada cabecera, "b" puede decir taxativamente flaco, ahora tengo 16k, 15k, 14k, y lo escribe, lo escriben las cabeceras, 2k, 1k, 0, 0, 0. Con lo cual el lado transmisor dice, ups, la ventana es cero, no puedo seguir transmitiendo hasta que el lado receptor no abra la ventana de recepción, es decir, la aplicación del lado B, no consume y me despeje espacio de recepción de buffer, no voy a poder seguir transmitiendo. Ahora, si lo pensamos, eso solamente contempla, del lado transmisor, la situación del lado receptor, la situación esta de determinística de buffer, pero como bien sabemos hay otro jugador acá, súper importante, que TCP debería ser un poco cuidadoso. A ver, ¿qué pasaría si TCP tomara esta actitud como dijimos al principio? Imagínense, ¿no? El handshake acá, fla, fla, fla. Por cierto, vamos a ver luego que en todas las cabeceras va la ventana, incluso en este SYN, en este SYN inicial, en el primero, este lado dice, porque también tiene su buffer de recepción, como lo vimos, el lado A tiene su buffer de recepción, le va a decir ventana 32, imaginando que fueran iguales de un lado y de otro. En el primer paquetito que recibo de B, el SYN ACK S también me dice ventana 32, y después en el ACK final, ventana 32. Estamos todos de acuerdo que esto está despejado de ambos lados, porque de hecho estamos recién iniciando la conexión. Y de pronto dice, ¡uh! 32K, listo. La aplicación, la bestia de la aplicación escribió "Mega, tengo 32K, este es mi momento para lucir", me dijo el TCP transmisor de este lado y quizás del otro lado también, si es que ambos, si es que empiezan un intercambio direccional, y escriben los 32 segmentos, luego datagramas IP hacia uno tras otro. ¿Qué les parece eso? ¿Está siendo cuidadoso con la red? O está, mejor dicho, ¿está teniendo en cuenta que también está la red cuando toma esa decisión? El TCP debe decir, listo, el otro me publicó una ventana de 32K, yo tengo 32K para llenarle esa ventana, y se lo... Le tiro el 32 paquete de 1K. ¿Qué les parece? No, no le está importando nada. Bueno, ve. Ni tiene en cuenta la red. ¿Y qué pasaría si todos los TCP del mundo, o mejor dicho, todos los TCP que comparten esta misma, de comillas, "zona de red", decidieran hacer eso con cada inicio de conexión? Y se saturaría la red. Sería bastante desastroso. Y más aún si tengo cada vez máquinas más poderosas que tienen posibilidad de tener buffer recepción más grandes, ¿no? Blancar con un mega de buffer recepción. Imagínense que todos TCP dijeran "¡Wee! ¡Ay!" Y vamos a transmitir. Bueno, entonces, ¿qué es lo que apareció a medida que TCP se fue desarrollando? Apareció el concepto de una ventana, de una ventana heurística, ¿no? De terminística, que se llama ventana de congestión. La ventana de recepción en realidad contempla... No sé si pongo el ruido acá. No, no lo voy a... No me va a caer bien el dibujo. La ventana de recepción contempla un estado determinístico básicamente de esto. ¿Cuánto me está diciendo el otro lado que puede recibir, que tiene espacio libre en buffer? La ventana de congestión va a ser una ventana dibujada por el lado transmisor, en base a lo que huele de la red, de qué tan bien están dando. ¿En base a qué este TCP puede empezar a percibir "La red está... no está muy buena hoy, debería acá bajarle la rosca" o "La red está fantástica"? ¿Qué tipo de feedback puede tener TCP ahí para decir "Es IP que le va a ir diciendo su Squench, no, mirá, la red está fallando" y de pronto cuando la red se congestiona, la misma red empieza a gritar a todos los TCP que tiene en sus bordes "¡Ah, no, no, no!" ¿O será el mismo TCP que va como aprendiendo, que tiene que tratar de decir "esto no está muy bueno, tengo que adaptar acá"? ¿Qué les parece? Supongo que TCP porque IP no tiene la manera de hacer eso. IP no hace ningún aporte a la capa de transporte. ¿Y cómo sería si este TCP, este TCP de hecho, el que puede decir "esto no está muy bueno" o "esto está... qué tiene para...? Y si está retransmitiendo muchos paquetes. Bien, si está retransmitiendo mucho, el ritmo con el que llegan los hacks del otro lado. Y entonces ese feedback que tiene TCP de cuán bien o cuán mal está la red, va a ir ajustando esta ventana, yo le llamo ventana heurística porque no está... Está obviamente almacenada la transmisión pero nadie te dice acá, no hay un Dios que te diga "Che, loco, está bien, este te dijo 32K originalmente, pero yo, red, te digo que tenés 3K de ventana de congestión". No, este va a tener que ir diciendo y decir, "Uh, bueno, lo voy ajustando". Y siempre transmitir con el mínimo permiso de las dos ventanas. La ventana de recepción determinística, la que está del lado B. Y una ventana fantasmagórica, heurística, que yo como TCP transmisor voy a ir construyéndola en base a arrancarla en principio, ya vamos a ver que no es tan así, pero arrancarla con un máximo de la ventana de recepción del otro lado, y penalizándola, penalizándola significa bajarla a medida que veo que la red no se comporta bien. Pero siempre tratando de tender a abrirla y a que la ventana de congestión iguale a la ventana máxima de recepción, para decir, cuando la red está perfecta, la ventana de congestión iguala a la ventana máxima de recepción, la que leí en el primer intercambio, y cuando la red está mala, ¿a cuánto usted lo bajaría? ¿a cuánto le hacía martillazo al TCP? En este caso al lado A/B, diciendo "¡ah, horrible, horrible!" ¿Cuál sería ese número mínimo? De ventana, median bytes. La de 1. 1K, sí. Podría ser 1 o 1K, no es lo mismo. 1 es un byte, 1K es un MTU, estamos hablando de 1.5K, para ser más precisos. ¿Cuál de los dos? Lo dejamos picando y lo vemos ahora. Se los dejo picando porque es un tema interesante. Bueno, vamos a ver entonces, ¿qué es lo que vamos a ver en estas dos nuevas diapos? Un montón de... ¿Conocen ese dicho en inglés que "el diablo está en los detalles"? O decir "¡Uh, mira qué bueno este protocolo, año 81, qué hicimos, anda fantástico hasta que no anda fantástico". Andaba fantástico hasta que dejó de andar fantástico. ¿Por qué el diablo está en los detalles? "Debilice in the details". Vamos a ver el primer fenómeno. ¿Por qué nos enfocamos en esto? Esto está muy bien explicado en el Internet Core Protocols. A nosotros nos gusta enfocarnos en esto, no porque queramos aprender todos los chirimbolitos que tiene TCP, pero lo que sí nos interesa es entender el problema porque eso va a afectar como yo escribo las aplicaciones y como yo le saco el mayor jugo a la red cuando tengo una aplicación bien escrita. Entonces, veamos qué es lo que ocurre acá. El primero que es Silly Windows Syndrome, que es del lado de recepción, es... ¿Qué pasa? Imagínense la situación esta que venimos hablando reiterativamente de que A está empujando a lo bestia, tiene un montón para transmitir contra B, buffer de transmisión lleno, y acá tenemos la situación de ventana cero y esta aplicación le da un byte por segundo. ¿Por qué? Porque está programada así, o porque no sé, o la programaron mal, o tiene un bug y viene, tiene un loop, main loop, y el flag con el main loop le hace un read del FD, tamaño 1. Entonces, la situación es, todos estos buffers de transmisión de A hacia B y de recepción en B, obviamente, están llenos. Yo los fotografío y están llenos. Y la aplicación viene y cada un segundo hace... saca un byte y lo procesa. Espera un segundo... y hace un read de un byte y lo procesa. Si ustedes son estrictamente TCP, ¿qué harían acá? Con lo que hemos aprendido hasta ahora. ¿Qué novedad tiene el lado B, al cual le han despejado un byte de su buffer lleno? Tiene una novedad ahora. ¿Cuál es la novedad? La ventana. Ajá. Antes era cero y ahora es... Un byte. Uno. Un byte. Ojo, no un "k", es uno. ¿Qué debería hacer B? Para seguir con lo que hemos aprendido del protocolo hasta ahora. Palabra clave, publicar. ¿Qué debería hacer B? A estaba parado porque tenía ventana cero y ahora yo, como B, tengo una novedad. Y la app lo lee y le tiene que avisar al espacio que le queda. ¿Cuánto es ese espacio? Uno. Perfecto. Entonces, si yo sigo estrictamente el protocolo sin ningún hack, yo como B debería decir "¡Uh, buenísimo! Estábamos ventana cero, ahora tengo ventana uno". Agarrar, armar un mensajito de TCP con cabecer y decirle "Che, tenés ventana uno ahora". ¿Y A qué debería hacer? Siguiendo lo que hemos aprendido hasta ahora. Intentar enviar uno. Envía uno. De los 32 "k" que tiene lleno y todo lo que tienen para arriba, agarra, toma un byte, le pone una cabecera de 20 bytes de TCP mínima, le pone una cabecera de 20 bytes de IP mínima y envía ahí un divino mensaje, un datagrama que mide 41 bytes y lleva un byte de data, que fue lo que se había despejado en el buffer de B. Llega hasta B, imaginemos que la distancia networkeana entre los dos es de pocos, 100 milisegundos o 200 milisegundos, ponle lo que quiera. La aplicación, recordemos que le haría un byte cada un segundo. Estamos muy abajo de eso, estamos a 100 milisegundos de round trip time. Por lo tanto, le llegó, reaccionó, envió, con lo cual es como que la aplicación enala un byte y a los 100 y pico de milisegundos ya tengo el buffer lleno de vuelta porque hizo "ch, ch, ch" y le dijo "eh, hay un byte libre, buenísimo, ahí te vivo" Vienen los 41 y se llenan. ¿Va a haber algo que corrija en el futuro? Primero, ¿qué tan bueno está este comportamiento? ¿Qué les parece? No, está malísimo. Horrible. ¿Por qué es horrible? Porque para enviar un byte estás enviando 40 más. Básicamente tiene un ratio de 2,5%, 1 sobre 40, y 1, bueno, más o menos. 2,5% de uso de la red para enviar datos. ¡Espantoso! Te sacaste un 0 TCP. Lo que es interesante es que, al menos que TCP tenga un hack, si TCP se comporta como hemos aprendido hasta ahora, este va a ser un comportamiento catatónico que va a seguir para siempre. Porque la aplicación va a seguir leyendo cada un byte, cada un segundo. "Ch, ch, ch" Ventana, "ch, ch, ch" Y se va a venir, se va a llenar rapidito con un byte. Y tuvo que bajar un montón de overhead ahí. Listo, y la aplicación lee de la punta del buffer y después se le llena la colita al buffer a los 100 y pico milisegundos y después se le llena de vuelta. Y en realidad ese uso final va a ser horrible de la red. Siendo que encima, esta aplicación tiene 32K menos un byte todavía para consumir y este tiene también como los 32K para enviar. Así que no le agregan nada que llegue ese byte atrás de todo esto que había para hacer. Entonces, este es el primer caso que es el más sencillo de entender de los hacks que aparecen. No son hacks, son en realidad implementaciones dentro del protocolo de TCP para evitar esto, porque si no, ¿qué alternativa queda a TCP? Hacer la gran alternativa de TCP papiestado, es decir, prohibimos las aplicaciones que leen de un byte cada un segundo. Listo, plum. Están prohibidas. Estoy obviamente teatralizando algo estúpido. Tengo que poder soportarlas, pero tengo que poder soportarlas bien. No tengo que poder, no tengo que tener, de vuelta, que cargar a la red IP con un mal comportamiento de la aplicación. Es mi misión como capa de transporte hacer que esto funcione bien incluso cuando tengo una aplicación estúpida. Eso es súper importante. Entonces, ¿qué hace? ¿Qué hace TCP? Miente. Miente. ¿Cuál sería esa mentira? ¿Dónde estaría esa mentira? ¿Quién es el primero que tiene que mentir acá? Si hay algún intercambio de paquetes, tengan presente, que por cierto que esto fue nada más que de A hacia B. Acá pueden estar fluyendo perfectamente paquetes de B hacia A, entre el verde y el rojo este. Por lo tanto, hay AX en ambos sentidos. El AX va siempre, ya vamos a ver. Excepto en el primero, que es un SYN. No tengo que hackear, pero después siempre viaja AX. Entonces, en esos intercambios, cuando el lado B tiene que decir "y mi ventana ahora es 00001", 1, 1, 0, 0, 1, 1, 0. ¿Qué podría ser B ahí? En todos estos intercambios, ventana 0. Acaba de despejar un byte en el buffer. ¿Qué ventana le digo A? Para que no sea tonte. 0. Devolver un byte a la última. 0. No, está bien, sí, ok. Ok, buffer, sí, sí. Todo lo que vos quieras. Tenés un byte, tenés dos bytes, tenés tres bytes, tenés cinco bytes, tenés cien bytes. Ventana 0. 0. Tenés 200 bytes, 500 bytes. Ventana 0. Y miento, miento, miento. ¿Por qué no tiene sentido? Porque tengo una ventana de 500, tengo todavía 31 IP, 31... ¿Para qué le voy a dar una ventana más chica al otro que se va a venir como loco a transmitirme? ¿Cuál sería un buen punto de inflexión cuando ya dejo de mentir? ¿Cuándo debería ir? ¿Cuándo yo, como B, empiezo a decir "ah, sí, sí, sí, ahora sí hay ventana"? No sé, la mitad o por ahí. Bien, es una buena idea la mitad. Pero, ¿cuál es el paquete más interesante, más gordito que puedo enviar a la red, que mejor utiliza la red? Y esa va a ser nuestra unidad de... Vamos a ver que toda la furia de TCP, que vamos a estudiar todos estos hacks, un PMTU, muy bien, un PMTU, un PASMTU, ¿no? Entonces, TCP ya ha aprendido para el estado conectado. Está aprendiendo cuál es el PMTU, y es una memoria que tiene ambas puntas, tanto A como B memorizan los PMTU. ¿Qué va a ser típicamente el mismo? Muy raro que sea distinto, el mismo va a terminar memorizando, va a aprender el mismo PMTU. Imaginemos, ese PMTU va a ser típicamente 1.500, imaginemos para simplificar lo que estamos hablando y los números, un K de PMTU entre ambos lados. Entonces, nuevamente, la aplicación recuerda, ¿no? Lee muy lentamente de a un byte. Pero acá hay intercambio de segmentos de un lado a otro y de cabeceras. Lado B dice 0, 0, el buffer tiene 100, 0, el buffer tiene 800, 0, el buffer tiene 1.200. ¡Ah! ¿Cuánto le pongo de ventana al otro lado? 1.200 le digo. Es como que no empiezo a publicar la ventana hasta que el otro lado, que no sea mayor que un PMTU. Y eso va a hacer que el otro lado reacciona, el lado transmisor dice, ¡uh, buenísimo! Tengo 1.200, voy a poder armar un paquete de un K y ahí aparecerá otro retoque de si vale la pena o no vale la pena enviar esos 200. En realidad va a enviar esos 200 al estado de orden, hasta donde yo sé, mandaría el un K y otro K de 200 también. Pero lo importante es que esta idea de mentir para proteger a la red. Y vamos a ver que todas estas optimizaciones están, de alguna manera estos son hacks, son ajustes de TCP para proteger a la red. Cuando esto se empezó a implementar, se implementó en el lado recepción. ¿Y cómo sería una implementación también protectiva o defensiva, mejor dicho, del lado transmisión? Lo que estamos viendo es una implementación defensiva del lado recepción. Esto de mentir y solamente publicar un buffer, una ventana de recepción, una vez que supero un PMTU. Y del lado de transmisión, imaginando que tengo un TCP mal implementado del otro lado, muy simple, un sensorcito, que se yo, que no implementó el SWS, se llama esto. Silly Windows Syndrome. ¿Por qué? Porque es como ventana, síndrome de la ventana tonta, por esto de que es una ventana de uno que se va transmitiendo, obedeciendo el caso original. Ahora lo tenemos arreglado en el receptor, pero imaginemos que no lo tuviéramos arreglado en el receptor. ¿Hay algo que el transmisor podría hacer? Si el receptor en realidad con cada intercambio va diciendo, "Ay, sí, ahí hay una ventana uno, ventana dos bytes, ventana tres, ventana cuatro, y yo soy transmisor. ¿Qué puedo hacer en forma defensiva frente a eso?" Y hasta que no me dicen que tiene una ventana de un PMTU, lo mando. Exactamente, tal cual, tal cual. Entonces fíjense que hay como implementación del lado receptor esa mentira, pero el lado transmisor también tiene que ser cuidadoso y decir, "No, flaco, ok, sí, vos decime dos, tres, cuatro, cinco, pero hasta que no venga un caca, Milky, hasta que no me digas Milky, yo no te mando nada. No, no, no. Porque acá tengo todo esto bufereado hacia arriba, sí. Una cosa distinta sería si no tuviera nada bufereado y también está ese concepto. Entonces, habiendo entendido conceptualmente cuál es el problema, acá vienen las reglas. Entonces, publico ventana cero hasta que la ventana, acá en realidad debería ser mayor o igual a un PMTU. Fuck, shit. Mayor o igual a un PMTU. O, y acá hay un concepto que típicamente uno no lo ve, uno no lo ve, pero alguno de ustedes nos mencionó que estaba muy bien cuando la ventana sea la mitad. Pero eso es para una ventana chiquita. Imagínense ventanitas de un K que nunca vamos a llegar a un MTU, sí. Imagínense una implementación muy, muy restringida en memoria, no. Nuevamente, más difícil de verla hoy en día, pero algo acá que tengo un buffer recepción, no sé, o vamos a hacer distinto, de 2K, es bastante arriesgado esperar hasta que pasen los 1500 de PMTU para decirle "ya tenés ventana". Entonces ahí se pone una regla, o que puede ser un MTU, o que toques más allá de la mitad del buffer, que fue un criterio que alguno de ustedes mencionó que está muy bien. Cualquier de las dos condiciones dispara la actualización de ventana al lado receptor. Bien. NUG lo vamos a ver después del recreo porque es un poquito más complicado. Es más tricky de entender. Vamos a ventana de congestión y la vamos a... Yo ya les presenté esta idea de la ventana de congestión y fíjense cómo se penaliza la ventana de congestión. Imaginemos una situación en donde hay un flujo normal entre ambos lados, ¿no? Es decir, acá hay... Asumamos por simplicidad de que A está transfiriendo a B. Todo fluye normalmente, fluye hermoso. Y si saquemos esta aplicación catatónica, imaginemos que tenemos una aplicación ágil del lado B que está consumiendo el buffer recepción y esto se da, va todo bien y no hay pérdida. En esa situación, la ventana de congestión tiene el mismo valor que la ventana máxima de recepción que yo había medido. En el inicio de la conexión. 32K. Eso está señalizando, y la pongo horizontal para tratar de hacer una mímica de que la ventana de congestión está acá, ¿no? Representa la red. Y la ventana de recepción representa el tamaño del buffer libre. Entonces, tenemos una ventana de congestión de 32K. Esta ventana de congestión en realidad se va adaptando también a la ventana de recepción, ¿sí? Si la ventana de recepción está arrancó en 32K, después se bajó a, no sé, 20K, la ventana de congestión, en un caso de sin pérdida, se va siempre adaptando. Ahora, ¿qué pasa? La ventana de congestión, se supone que no es una copia de la ventana de recepción, es una copia penalizada de la ventana de recepción, penalizada por situaciones anómalas de la red. Y es así como se va penalizando. Fíjense, si hay un act duplicado, ahora lo vemos, ¿qué significa act duplicado? La ventana de congestión se penaliza a la mitad. Si yo vengo a Hermoso, imagínense que veníamos con una ventana estable, 32K era cuando estaba vacía, imagínense que la logro tener 20K. Si tengo un act duplicado, el lado transmisor va a decir, ups, act duplicado, la corto a 10K. Y es como que yo, arbitrariamente, mi ventana de congestión ahora es la mitad. Es 10K justamente porque observé un act duplicado. Y si tengo un act timeout, y esto es lo más loco de TCP, si TCP, el lado transmisor, observa un act timeout, es decir que no me vino el act en tiempo, la ventana de congestión se baja a un MTU. Así de violento es. A un MTU. Estábamos quizás en unos divinos 20K o 32K, si estaba totalmente espejado el buffer, y tengo yo el lado transmisor act timeout, y la corto a la ventana de congestión, y solamente me autopermito, por la ventana de congestión, un MTU, un PMTU. Y después voy a tener que pelear por subirlo. Esto más o menos sería así. Vamos a ver si me sale el dibujo. Vamos a hacer dos ejes. Este eje es el tamaño de la ventana, y vamos a ponerlo a las dos. Este eje es tiempo. Imaginemos que... ... ...esta es la ventana RX. Es decir que esta altura sería estos 32K que veníamos hablando a modo de ejemplo. Y lo que voy a dibujar, y esta es de alguna manera fija, vamos a asumir la fija por simplicidad, que la estamos viendo fluir naturalmente y bien. La ventana de congestión va a seguir entonces un tránsito más o menos, yo lo voy a dejar acá en azul, arranca ahí, va todo bien, pero se baja acá, a la mitad, bajo un evento de ACK duplicado. Se baja a la mitad, ya vamos a ver cómo se vuelve a levantar, tiene un comportamiento como suave al levantarse. Yo por ahora lo voy a dibujar así, de manera semilineal, se va a ir levantando, un evento de ACK duplicado. Recordemos acá a modo de ejemplo, imaginemos que estos son, por ejemplo, estos 32K que habíamos hablado, para tener una idea de número más o menos. Por lo tanto, con un ACK duplicado, se le baja a la mitad, acá baja a 16K. ¿Y qué pasa si tengo un evento de ACK timeout? ¿Cómo debería seguir dibujando esta línea? ¿Qué les parece? Estaba tratando de levantarla, imaginemos que logró levantarla y llevarla de vuelta, y ahora viene un ACK timeout. ¿Qué ocurrirá con la ventana? Baja el P, venta. Así de violento. Tuk, acá. En donde esto es, entonces. Timeout. ACK duplicado. Ya estudiamos enseguida, por qué ACK duplicado tiene un sabor, hay un problemín. Y ACK timeout es más fácil de entenderlo como que hay un problemón. Pensemos que ACK timeout es que desapareció el otro lado. Crasheó el nodo, no obtuve ningún otro tipo de feedback del otro lado, no estás del otro lado para mí. Porque si no me hackeas, si me dio timeout, estaba esperando que me hackee, y no llegó, para mí no existís. O dejaste de existir. Entonces, por eso es que, vamos a ver, entonces, acá. Y ahora vamos a ver enseguida, por qué este T7 tiene un comportamiento, más o menos así, una primera parte exponencial, y otra segunda parte lineal. Pero este ACK timeout, esta altura acá, va a ser un PMT1. A ver cómo lo podemos dibujar. Actube, entonces acá le vamos a poner, WB, Fx sobre 2. BK, esta altura acá. Un PMT1 de altura. Poner acá entonces, sobre la X. ¿Entienden? ¿Ustedes han percibido esto? ¿Les suena cuando la red está...? ¿Qué es lo que uno tiende a hacer cuando, cuando, si esta página está lenta para cargar? La recargas. Y generalmente tiene más éxito recargarla o no. Digamos, el tiempo final. ¿Suele convenir esperar que eso se recupere, o suele convenir recargarla? Típicamente, ¿no? ¿No? Yo a mí a veces siento que si la recargo, a veces que mejor. Y es por lo que estamos viendo acá, justamente. Esta memoria que tiene TCP de que este socket ha tenido un problema, y que se ha presentado una situación de ACK timeout. ¿Sí? ACK timeout provocó esto, y el ACK loop provocó esto. Este ACK timeout me hizo que este socket, esta conexión, que memorizara que acá ha habido un problema, y la recuperación es muy lenta. En general, es más, suele ser, ya vamos a ver que no es general, no es necesariamente así, pero suele ser más fácil romper ese socket, y decir "ah, esta conexión está espoileada, está embrujada", y directamente empieza una conexión fresca desde cero, que arranque sin memoria, que no arranque con una memoria de que había tenido un problema, que no arranque de una manera penalizada. Porque no solo eso, sino que este PMTU, y acá voy a tener que aumentar los tiempos de retransmisión. TCP, cuando retransmite algo que se perdió, y ahí va una pregunta interesante. Cuando yo tengo, yo soy TCP, hay un ACK timeout, estoy penalizado a un PMTU, por lo tanto puedo transmitir un solo segmento grandote, un PMTU por vez, a pesar de que tengo un montón, esa es mi vida, mi penalización, mi ventana de congestión me dice un PMTU. ¿Cada cuánto lo retransmito? Tengo que retransmitirlo, ¿no? Si yo había transmitido todo un pedazo de una secuencia de segmentos que representaban todo un espacio de secuencia interesante, ACK timeout. Me bajo a un PMTU. Retransmito. Si el otro lado en RTT estaba a 100 milisegundos, ¿qué hago? Retransmito cada 110 milisegundos, retransmito cada 110 así. Y me quedo ahí medio en modo TOC, modo así obsesivo-compulsivo. Y todos los TCP que hay alrededor de este problema de congestión de la red, todos... ¿Qué deberían hacer TCP ahí? Además de que ya está restringido un PMTU, el ritmo de retransmisión. Y no sé, porque si hay un timeout, puede que se haya apagado la computadora del otro lado. Sí, sí, sí, no puedo saber nada, no me vino ninguna señal, así que yo soy TCP transmisor. La pregunta es, si el otro lo había medido a 100 milisegundos, me dio ACK timeout porque esperé, no sé, 125 milisegundos, ya veremos, vamos a ver, 100 más X milisegundos, y no vino y retransmito. Y con la penalización de ventana que estamos viendo ahora. La pregunta es, retransmito, yo había esperado, no sé, 125, retransmito, espero 125, retransmito así, chup, chup, chup, chup. O tengo que, no solo cambiar la dimensión tamaño, sino cambiar la dimensión tiempo, y ser también gentil con el ritmo de retransmisión. ¿Qué les parece? ¿Qué pasaría si esa red que está congestionada, hay pérdida de paquetes? Yo no sé si es el nodo que se fumó, o la red que se comió mi, yo no sé qué pasó, ¿no? Ventana y congestión a mí me ayuda porque mi asumpción es que es la red el problema, no el destino. Entonces, bajo asumir que es la red el problema, yo tengo que proteger la red. ¿Qué pasaría si todos los TCP quedaran en un PMTU, pero mantuvieran ese ritmo de transmisión muy similar al de RTT que habían medido antes, al round trip time? Yo chik, chik, chik, y todos mis hermanos chon, chon, chon, y todos sus primos chon, chon, chon, chon. Y no bajaran el ritmo, no dijeran "eh, eh, eh, eh, para que te llegue el AC, tranquilo, no seas tan toc TCP". ¿Qué significaría eso en la implementación del tiempo? ¿Qué harían ustedes? ¿Eran 100 milisegundos en el próximo intento? ¿Cuántos harían? 200, no sé. Bien, 200, no pasó nada todavía. ¿En el próximo? 300. ¿Y si quisiera ser más gentil con la red? 400. ¿Quién es la mejor apuesta? El doble, ok. ¿Y en el próximo? 800. Bien. Y llegó hasta un punto máximo, ese punto máximo está en alguna referencia que creo que son 30 segundos, una cosa por el estilo, pero ese mecanismo se llama "exponential back off". Quiere decir que yo me freno exponencialmente. Y es algo que tenganlo presente siempre cuando ustedes se estén tratando con este tipo de problemas. Tienen que pensar en la escala del problema. Tienen que pensar en qué van a hacer todas las instancias de su aplicación. Acá estamos viendo el protocolo de transporte, ustedes no tienen que pensar esto porque ustedes duermen cómodos como aplicación que TCP se encarga de hacer toda esa retransmisión. Pero es importante que, si TCP no tiene ningún feedback del otro lado, entonces, pará, pará, pará, pará, pará. Dejemos que esto se recupere. Entonces, tengo que bajar todos los ritmos de transmisión que yo tengo, al menos, contra este destino. Y para bajar el ritmo, si yo estoy limitado a un PMTU, la única manera de bajar la velocidad de transmisión es aumentar el tiempo. Velocidad es tamaño dividido a tiempo. La dimensión que me queda es tiempo. Y sabiendo que la red, además, es sensible a cantidad de PPS, no solo a la cantidad de paquetes por segundo, no solo a la cantidad de data que muevo, entonces, yo me empiezo a estirar en el tiempo y empiezo a bajar mis expectativas de que la red tenga la posibilidad de pasar eso, Exponential Backoff. Cuando uno hace F5 o Control+R para recargar una página, fundamentalmente, el PMTU todavía se sostiene, ya vamos a ver por un fenómeno que vemos ahora enseguida, pero lo que se resetean son los timers de transmisión. Es Exponential Backoff. Eso que uno observa que, uc, esa página se quedó en, blin, cargando, así, se quedó, cum, cum. Y se quedó ahí, ¿por qué? Porque tengo los Exponential Backoff del otro lado, el lado, por ejemplo, si es un web server que está intentando transmitir y, hay algo de pérdida, capaz que perdió uno de mis hacks, y, tac, tac, está haciendo el Exponential Backoff. Pin, pin, pin, pin, pin. Está estirando los tiempos. Yo cuando hago F5, es como que arranco fresco desde cero. Y arranca el, el, el timer de retransmisión del otro lado, va a arrancar en un RTT, en lo que memorizó de a qué distancia de tiempo. Por eso, es como que, hago una trampa, corto ese Exponential Backoff, y al arrancar la conexión fresquita desde cero, arranco con un, con un timer de retransmisión mucho más bajo. Y con eso, dependiendo, obviamente, del estado de la red, y si la red es capaz de, de, de absorberlo, generalmente tengo más éxito. Y esa es la razón por la cual un recargar algo funciona. Funciona mejor. La razón es que le hago trampa al Exponential Backoff. Bien. Entonces. 19.31. Hagamos un recrédito. ¿Qué nos queda? ¿Nos quedan estas dos? No, estas son, son relativamente rápidas. Sí, no podemos terminar hoy y ver, al menos hacer un preview de la cabecera. Hacemos un recrédito, son las y media, volvemos a la, y 31, volvemos a la -10, ¿eh? 8-10. ¿Rearrancamos? Bueno. Antes de ir al recreo, ¿alguna duda de esto que hablábamos hasta ahora? No, está, para mí está bien claro. Está bien claro y curioso. Sí, es muy interesante como me ponen la lupa ahí abajo, porque uno nuevamente está sentado como en la aplicación, haciendo push. Bueno, en eso le meto write, todo lo que tengo, todo tal. Y en realidad hay maneras en las cuales uno puede sacarle mejor jugo al ritmo de la red. No, no se quiere presionar tanto TCP, entender lo que pasa abajo, y no pensar que es una manguera infinita de bytes, sino, mmm, esta manguera está paquetizada abajo, entonces tranqui, veamos cómo hago la aplicación cuando escribo, cuando leo, para que fluya mejor. Así que, bueno, por eso es que nosotros nos consideramos importantes tener esta lupa en que pasen transportes. Bueno, paro la grabación y ya obviamente hacemos una nueva cuando volvamos. [AUDIO_EN_BLANCO]