Retomamos entonces esto que estábamos viendo, cuáles son de alguna manera los... En realidad, hacks no son hacks, pero esto es lo que ha tenido que implementar TCP y aprender de los implementadores, de los diseñadores a lo largo del tiempo para tratar de ajustarse a las condiciones del mundo real. Y especialmente en lo que refiere a las condiciones de la red. Vamos a ver el tema de los hacks duplicados porque es interesante. Y esto es tan, tan, tan fácil. Me buscaron una pizarra normal y no es esto. Cuando podremos volver. Anyway, imaginemos esto que es todo un pedazo de espacio de secuencia. Recordemos que para lo que es data, para la aplicación, para el TCP es un problema de espacio de secuencia. Imaginemos que TCP ha tenido que cortar este espacio de secuencia en eso. Eh, Diego, ¿cómo estás? Buenas noches. No estás presentando nada, te aviso. Mira que bien, pero me encanta verme a mí mismo. Gracias, gracias. Ahí vamos, ahora sí. Bien, entonces recordemos para TCP el problema es espacio de secuencia. Lo que para la aplicación es data, para TCP es espacio de secuencia. Tengo que empujar desde el lado, al otro lado de esa es mi misión. Bien, entonces imaginemos todo ese espacio de secuencia y tiene que empujar TCP de un lado a otro. Lo que yo he puesto verticalmente ahí como cortes es los PMTU, que es la mejor unidad en que TCP puede segmentar esto para hacer estos problemas en unitario, si se quiere. Es decir, cada segmento ahora es mi problema. Pero internamente TCP siempre sigue pensando en bytes, espacio de secuencias. No, entonces si uno pusiera acá, entonces nosotros estábamos redondeando por hacerlo cómodo, como si fuera un PMTU de aproximadamente de 1K, entonces imaginemos que esto es 1K. Bien sabemos, insisto mucho en eso, porque a veces, de acuerdo al humor del día, nosotros somos más o menos insistentes con ser más precisos con los 1,5K, pero bueno, imaginemos, entonces un PMTU de 1K. ¿Qué irá pasando en los distintos momentos de tiempo? Esto es el espacio de secuencia que tiene el TCP, ya lo ha recortado en sus segmentos y empieza a enviar segmentos. Entonces, le vamos a poner este segmento 1, 2. Ahora vamos a hablar en los segmentos. Entonces. Vamos a ir switchando entre segmentos y espacios de secuencia. ¿Qué irá haciendo TCP? Lo que ustedes se imaginan. Vamos a ver cómo me sale. Toma esto. A ver cómo se puede dibujar mejor esto. Imagínense entonces, este espacio de data, TCP ya lo toma en espacio de secuencia, ya ha ido enviando, es decir, ha ido enviando uno tras otro. Estos segmentos a destino. Normalmente imaginamos de izquierda a derecha. El destino, lo que hace a medida que va leyendo esto, imaginemos que los va leyendo sin errores, a medida que llegan, ¿qué irá haciendo el destino? Acá yo no quiero hacerlo, pero no sea tan largo, por eso sería, hagámoslo, no sea tan babo-franco. Es decir, esto ocurre en un momento de tiempo, imaginemos la línea de tiempo que va hacia abajo, como lo veníamos dibujando. Imaginemos que tenemos una situación de ventana de congestión muy favorable, con lo cual esto puede salir casi uno detrás del otro. Es decir, en este flujo que había en este grafo, estamos, por ejemplo, acá, azul, que es la ventana de congestión. Está bien abierta, y también la ventana de recepción, obviamente. Por lo cuanto yo, imaginemos que tenga una ventana generosa de 4K, que yo la he ido aprovechando. El lado transmisor lo que hace es enviar cada uno de estos segmentos. ¿Qué va a ir haciendo el lado receptor? El lado receptor va a ir hackeando al espacio de secuencia que haya podido consumir exitosamente. Es decir, ¿ustedes dónde lo dibujarían a los hacks? Para ser bien, bien precisos. ¿Dónde deberían ir esos hacks? Hola. ¿Dónde estamos arreglando las líneas, supongo? Si estos hacks vendrían acá. Una vez que el lado receptor ha podido consumir completamente, ojo, fíjense que acá la flechita esta viene arriba de este, porque bien puede ser que el hack, lo vamos a hacer incluso más evidente, que el hack a esto haya venido mientras se estaban transmitiendo los otros. No tiene por qué ser super serial o secuencial, ¿no? Es decir, a medida que se van enviando, van llegando los hacks y siguen enviándose. Bien, imaginemos entonces qué significa este hack a un K. Significa que el receptor pudo consumir ese un K, correcto. Lo que es importante saber es que los hacks son acumulativos al espacio de secuencia. No te hackea el paquete, sino te hackea espacio de secuencia consumido. Por lo tanto, este hack acá va a decir, yo te hackeo a 2K+1. ¿El +1? Es una cuestión meramente de sintaxis. Perdón, un K+1, disculpenme. Un K+1. El hack se escribe como el siguiente byte que estoy listo para recibir, más que el último byte que te recibí bien. Pero es una cuestión meramente de cómo se escribe el protocolo, no es semánticamente nada, es sintaxis, nada más. ¿De qué numerito te pongo ahí? Si es todo lo que consumí o el próximo momento libre. Bien, es el próximo que estoy listo para recibir. Seguimos con esto. Este hack, ¿qué dirá del lado del receptor? ¿Qué les parece? 2K+1. Ajá, 2K+1. Dice hack 2K+1. Y ocurre que al 3 le cayó el rayo, rayo disante, y ya. Y el 3 está kaput. O mejor dicho, el 3 estaba como dato, pero este se pierde. Y el 4 llega. Entonces, ¿qué pasará? ¿Qué les parece? Cuando llegue el 4 al lado receptor, teniendo presente que tiene una sola línea de espacio de secuencia para hackear. ¿Qué hackearía? Llegó 4, faltó el 3. Una cosa por decir. Mi no tener cómo decir eso, lo siento. Ya vamos a ver la cabecita, tiene nada más que 20 bytes. Y diciendo que llegó el 4 y no habiendo dicho... Mi no poder decirlo, mi solo poder decir todo lo que he leído correctamente hasta ahora. Y nada, hackea el 4. Uy, pero estoy mintiendo, loco. El 3 nunca llegó, ¿cómo es que hubiera que ir al 4? Entonces, no le mando nada y espero porque tal vez... No, porque eso es hack time out. Sabemos lo horrible que es el hack time out. No hagamos hack time out. Yo estoy vivo, no he desaparecido de este planeta, estoy ahí. ¿Qué es lo más que puedo decir? Así con cara de histérico. ¿Qué es lo más que puedo decir? Volver a mandar el 2. Y sí, no queda otro bloco, ¿qué le vamos a hacer? Entonces, eso es lo que efectivamente ocurre. Cuando llega el 4, lamentablemente no puede hackear el espacio de secuencia 4. Por lo tanto, en este momento de tiempo estamos yendo hacia abajo. En realidad, el tiempo fluye hacia abajo, este se perdió. Va a venir, lamentablemente, otro hack 2+1. Y ese es el origen del hack duplicado. ¿Por qué es el origen del hack duplicado? El TCP transmisor no es ningún tontín. Y dice, "Oh, oh, oh, acá hay hack duplicado". Quiere decir que yo puedo inferir que hay paquetes en el medio que se han ido perdiendo. No sé si el 3, ni hablar que si acá ha habido... Obviamente, si esto ha seguido hacia adelante. Y acá, yo lo hice por super simplificarlo, pero bien podría ser que esto acá, toda una secuencia de segmentos. Y yo sigo, "tuc, tuc, tuc, tuc, tuc". Hack duplicado. Si ustedes recibieron varios hack duplicados, por ejemplo, en esa posición, ¿qué podrían inferir? Yo soy transmisor, ¿no? Recuerden, yo no soy Dios, no veo todo el universo. Yo veo lo que yo puedo enviar y lo que leo al recibir. Envieso 6 y recibí 2K, 2K, 2K, 2K, 2K. ¿Qué pasó acá? ¿De qué puedo estar seguro yo como transmisor? Puedo suponer que no haya llegado al 3. ¿Que no haya llegado al 3? Claro, puede ser el 3 o el 4, pero estoy casi seguro que el 3 no. Ahí vamos a ver que puedo ser optimista o pesimista. La visión optimista sería, "Hm, seamos optimistas del 3 nomás, el que no fue, reenvió el 3". La visión pesimista es, "Se perdió el 3, el 4, el 5 y el S-Hack duplicado corresponde a 6. No tengo manera de correlacionarlo. Sí, ya vamos a ver la cabecera, no me da tanta info". Que siempre, como en todo diseño, es un trade-off, ¿no? Un compromiso. O inflo la cabecera con super información, con todos los detalles, o lo optimizo para el caso más común que es que no haya perdido. Y esa fue originalmente la decisión de diseño que hicieron los creadores del protocolo. Entonces, de todas maneras, lo que es importante en este momento es entender el origen de los hacks duplicados. De hecho, en este escenario, ¿cuántos hacks recibiría? Duplicado. Imaginando que todos pasaron excepto el 3. Solamente el 2. Ok, sí, sí, no puedo avanzar del 2, esto está clarísimo. Pero imaginemos que lleguemos al 4, al 5, al 6, ¿cuántos hacks duplicados recibiría? Es decir, este, cuando fue procesado por lado receptor, me renvió a este. Este, cuando fue procesado por el receptor, también no le quedó otra que decirle acá, es decir, 3 más, ¿no? Es decir, que hay como 3 duplicados. Y este, el 6, no le quedó otra. Quiere decir acá, sencillamente porque no tengo yo como lado receptor, a la derecha del dibujo este, no tengo ese pedacito y me falta, así que me quedó ahí. Entonces, fíjense. Y ahora sí volvemos al tema de la penalización. Pero, ¿por qué eso? ¿Por qué esos están duplicados? El 4, el 5, el 6, si cuando se perdió el 3, no le mandé el del 4, le volví a mandar. Yo todavía no mandé el 3, ojo. Ahí, yo envié toda esta ristra, que era lo que me permitía la ventana de congestión y de recepción en este momento, mínimo las dos, me permitían enviar eso 6K, tac, tac, tac, lo envié. Y ahora espero un hack al 6K+1. Pero me viene hack al 1K+1, hack al 2K+1, pasa un tiempín y me viene hack al 2K+1, hack al 2K+1, hack al 2K+1. ¿Se entiende? No sé, ¿cuál es el cuestionamiento? Que todos esos repetidos, que o sea, llegó en 2K+1, ¿cuántas veces llegó? Montón, porque tantos como más allá del 3 hubo. Llegó uno, dos, tres veces. Que es lo que he tratado de dibujar acá con estos puntitos. Con cada uno de los OK, que lo pongo así como un check del lavador receptor. Vamos a poner una cosa. Así, con cada uno de los check, check, check, del lavador receptor me viene un hack. Pero como lamentablemente este es SPA es acumulativo, y no puedo mentir, no puedo dibujar que me llegó el 3, porque el 3 efectivamente acá vimos que se perdió. No me queda otra que pegarme acá. Esa situación es muy distinta a, yo como transmisor envío esta ristra y me viene hack al 1K+1, hack al 2K+1 y después cric, cric, cric, cric, cric, cric, cric, coinciden conmigo que es muy distinta la situación. El hack duplicado me indica, hay algo en el medio que se ha perdido. Se ha perdido un poco. Y un hack timeout, como bien venimos diciendo, puede ser se cayó totalmente en la red. Totalmente, parcialmente, es decir, en definitiva. Se cayó algo en el medio de origen-destino, o se cayó el destino directamente, no sé, qué sé yo. Si no tengo nada de feedback, puedo presuponer lo peor. Entonces, de ahí es que TCP tiene ese comportamiento de bajar a la mitad la ventana de congestión si hay hack duplicado y violentarla a un PMTU si hay hack timeout. Esto que habíamos dibujado acá. Déjenme, acá me faltó algo poner, escribirlo acá, que esta es la ventana de ese eje de congestión. ¿Con qué escribís? ¿Con el mouse? Sí. Muy bien. ¿Muy mal? No, no, no, digo al contrario. Muy buen pulso para escribir con el mouse. Y eso que estoy escribiendo con la derecha haciendo surdo. ¿Estás en tus licuadoras también? Sí, no, no, pero con este mouse vertical, obviamente. Bien. Bárbaro. Bien. ¿Se entendió, muchachos? ¿No? Es importante esto. Entonces, ahí se ve, fíjense cómo es recontra, caso particularense TCP. Si es un hack timeout, apunta un PMTU. Si es hack duplicado, a media, bajo a la mitad la ventana de congestión actual y así sucesivamente, si se hiciera falta. Y tiene un montón de estos casos particulares. Consecuencia, ¿qué onda la implementación de TCP? ¿Será así un pedacito de código en 20 líneas implementamos TCP? No, debe ser bastante largo. De hecho, si ustedes ven la fuente del código de Linux, por decir, la implementación de TCP es como 5 veces o no sé si más, debe ser, habría que verlo. En su momento eran como 5 a 7 veces la cantidad de código comparado con UDP. Y tiene timers por todos lados porque tengo que memorizar que había enviado este segmento para decir, ah, no, hay una condición de hack timeout, considerarlo como un evento, actuar en consecuencia. Un flor de despelote, fundamentalmente porque es recontra stateful. Si mantiene el estado de, fíjense que ahora mantenemos un estado per segmento. Acá, cuando nosotros empezamos acá, hablamos estado sin conexión, conectando, conectado. Pero si ponemos la lupa, TCP tiene que cuidar cada uno de los segmentitos que ha ido enviando y un timer de que hack timeout este, duplicado de este, reviento este, recalculo esto. Entonces, mucho estado. Muy gordo el cerebrito de TCP para cada una de sus conexiones. Eso es importante. Es decir, el hecho de tener un protocolo que nos hace, nos hace todo por nosotros, muchachos. Esto de retransmitir, asegurar que llegue ordenado, todo tiene su costo. Y ese costo es lo que estamos tratando de visualizar ahora. Slow start. Nuevamente, todas pequeñas cositas que tiene que hacer TCP para proteger a la que no conoce. ¿Quién es la que no conoce? A la red. Porque la red no habla. La red solamente o pasa o pierde. Slow start es lo que yo más o menos intenté acá. Es una manera en que TCP hace un, es loco porque le llama slow start, pero es el arranque de una exponencial. De una cadencia exponencial. Como ustedes saben muy bien, una curva exponencial tiene un inicio tranqui, slow, y después tiene una subida rápida. En la segunda pandemia, por ejemplo, o sea, alguna vez han visto con una pandemia. Veamos por qué. Aquí es interesante ver cómo es que el slow start implementa este inicio exponencial. La idea es que la ventana al arranque es efectivamente un PMTU. Es decir, sin penalización, sin haber habido act timeout, arranco la conexión asumiendo lo peor. Porque nuevamente todos los TCP tenemos que cuidarla que no habla, que es la red. Entonces yo arranco en lo peor. Arranco asumiendo que acá ha habido congestión. Arranco con un PMTU, pero arranco con los timers de los timers de retransmisión frescos. Timers de retransmisión frescos. ¿Cómo se yo? ¿A qué distancia está el otro lado? ¿Distancia? Es en realidad el tiempo. El RTP. El RTT. ¿Y dónde lo medí? ¿Cuándo lo medí? Me lo entrego una... Acá el primer SYN y ACK. Bien, perfecto. Acá ya tengo un feedback. Yo sé que el otro guacho está a 100 milisegundos. Entonces ya tengo una buena referencia para act timeout. Pero arranco penalizado, autopenalizado en slow start, en una ventana de un PMTU. Bien, volvamos. Ok, entonces vamos a ver cómo va saliendo esto. Imaginémonos que nuevamente tenemos todo esto para enviar. Tenemos estos cortecitos. A ver, déjeme, lo voy a cortar más chiquitito para que sea más gráfico. Pim, pim, pim, pim, pim. Si tengo un PMTU y esto ya está recortado en un PMTU, ¿qué es lo que puedo enviar? Uno de estos, ¿cierto? Esto es lo que va hacia allá. Un PMTU. Arrancamos con slow start. ¿Qué voy haciendo? Voy aumentando el tamaño de la ventana en base a la cantidad de ACKs que me van llegando. ACKs buenos, no ACKs duplicados. Si yo envié esto, me llega un ACK. ¿En cuánto aumento la ventana? En uno. En uno. Entonces acá teníamos que la window de congestión era uno. Estamos asumiendo entonces que acá me llegó un ACK. Me llegó un ACK. Por lo tanto, en el próximo estado que tenemos que la window es dos. Por lo tanto, yo avanzo acá y me autopermito a enviar dos. Bien, estos dos, si todo anda bien, ¿cuántos ACKs voy a recibir por estos dos? Uno solo. Pero en espacio de PMTU, medidos en PMTU, en unidades de avance de PMTU. Está muy bien. Podría hacer uno solo, de acuerdo al timing. Podría haber una optimización y decir, "ah, te llegaron juntitos, hacemos un solo ACK a todos". Pero imaginemos, pensemoslo en espacio de MTU. En principio, el otro lado me estaría ACKeando a este y a este. Antes me ACKaba acá. Por lo tanto, ¿cuántos ACKs tengo acá? Dos. Dos ACKs. Nuevamente, ya vamos a ver los detalles más íntimos del caso. Pero, si tengo dos ACKs y tenía la ventana en dos, ¿cuánto es la próxima ventana? Cuatro. Fíjense, esto ustedes ya lo están percibiendo. ¿Qué comportamiento va a tener esto? Tengo ventana... Exponencial. Ventana cuatro, significa, fíjense que acá yo estoy tomando el cuidado de dibujarlos, más o menos mapeándolo desde arriba del espacio de secuencia que tenemos que ir empujando hacia el otro lado. ¿Y qué pasará si ahora tengo cuatro ACKs? Recibe cuatro ACKs. ¿Cómo? No nada, recibe cuatro ACKs. ¿Recibe cuatro ACKs y cuánto va a ser el próximo tamaño de ventana? Ocho. Ocho, bien. Ahora, y fíjense nuevamente acá los tantos "if" que tiene el protocolo. "If, if, if, if". ¿Qué es lo que ocurre? Esto, como ustedes bien perciben, tiene un comportamiento exponencial, lo cual permite arrancar, que es lo que uno observa con el F5, lo que discutíamos recién, que pronto, "pfff", arranca rápido. Pero, para evitar esto que yo aquí dibujé como un comportamiento, esta parte, hacer esta parte más gentil, el "slow start" solamente es válido hasta la mitad de la ventana. Hasta la mitad de la ventana de recepción. Y ahí se para el "slow start", quiere decir que acá, que vendría a ser "windows" de Rx, sobre 2. Toda esta parte es exponencial y acá continúa alineada. La alinealidad se da en vez de sumar por cada "hack", en vez de seguir acumulando por cada "hack", acumula un solo salto de ventana cuando logró, es decir, ese aumento acá es solamente cuando logra pasar todo esto que había pasado acá. Eso quiere decir que va duplicando el tamaño de la ventana hasta un determinado punto, hasta la mitad de la ventana de recepción, y después de ahí empieza a aumentarlo linealmente. A medida que logra pasar esos 4, se permite solamente aumentar en 1. Cuando pasó los 5, se aumenta en 1 a 6. Cuando pasó los 6, se aumenta en 1 a 7. Para hacer ese comportamiento como exponencial y después, "chk", lineal. ¿Por qué? Porque el objetivo de TCP, asumiendo que la red esté bien, fíjense que acá no se perdió nada, acá no hubo ningún feedback negativo de la red. Esencialmente, TCP siendo cuidadoso en su arranque. Arrancar rápido y después tratar de lograr esto, donde esto es lograr que la ventana de recepción coincida con la ventana de congestión. ¿Cómo hacemos lo más feliz a un TCP el día de su cumpleaños? Le hacemos que la ventana de congestión sea igual a la recepción y un TCP va a estar contentito ahí trabajando hermoso. Cuando se enoja, cuando se pone en tristeza el TCP, con "act duplicated", con "act timeout" y se autopenaliza, se latiga y baja la ventana de congestión nuevamente para cuidar la red. ¿Quedó claro eso? Sí, bro. ¿Sí? Bien. La primera parte es "slow start" y la segunda parte es "speed". Disculpe, eso que dijo que era hasta 4 y después del 5, 6... No, ese número es un número esencialmente para recordar lo que dije, que es hasta la mitad de la ventana, no hasta 4. Bien, perfecto. Y hasta esto, esto, es W sobre 2. Eso era nada más por un ejemplo sencillo que yo tomé acá con los numeritos, acá. No es hasta W4, acá estaría asumiendo que 4 PMTU, justo la mitad de la ventana de recepción que me puso el lado receptor. Esto asumiría una ventana de 8K, por ejemplo, y yo llegué hasta 4, y entonces de ahí empiezo a subirla linealmente. Entonces, "slow start" con "congestion avoidance". Lo vamos a dejar acá escrito. Este periodo... De acá a acá es uno y este periodo de acá a acá es otro. Este periodo... Tengan presente que esto del "act time out" nosotros lo estamos dibujando acá es para ahorrarnos, deberíamos arrancar de cero en el tiempo porque la conexión arrancó fresquita, pero el fenómeno se repite. Mejor dicho, el comportamiento es el mismo. Entonces esto es "slow start". Por cierto, como les venía diciendo, el libro "Internet Core Protocols" tiene esto pero súper recontra claro. Y habla mucho más de lo que decimos nosotros, se puede aprender perfecto de él. Y esto es "congestion avoidance". Bien, seguimos. Veamos que otro retoque es "hacks" tiene TCP. "Delayed hacks". Alguien por ahí dijo, y con buen tino, de que acá por ahí TCP, el otro TCP podría dar el gusto de hacerme un solo paquetito de hack. Esto es que dibujé "hack" acá, "hack" acá. ¿De qué dependerá eso? ¿Qué les parece? Escenario, entonces, empuje uno. "Hack", "slow start". Empujo ahora dos, tengo permiso para dos. Y esos dos segmentos van muy "juntitos", entre comillas. Y le llegan al receptor casi, no simultáneamente, pero le llegan uno tras el otro al receptor. Entonces, ¿el receptor qué podría decir acá para ahorrar tráfico de regreso? ¿Qué les parece? Si el "hack" es inclusivo. ¿Que envíe solo el último "hack"? Claro, el último "hack". Porque como es inclusivo, como todo en estos tiempos, entonces, incluiría también a los "hack" anteriores. Entonces, alcanzaría con este y me puedo ahorrar este "hack". Y para eso, ¿el receptor qué tendría que hacer? ¿Tendría que ser impaciente o paciente? Impaciente. Le toca esperar a ver si llega más o no. Claro, exacto. Impaciente sería así tipo "talk", de decir, "me llegó bien, ahí va el "hack", me llegó el otro, ahí va el "hack". Entonces, ¿qué debería hacer? Y, pará, pará, tranquilo, tranquilo. Recibiste un segmento, lo chequeaste, hermoso, lo pusiste en el buffer porque no tenía errores, está listo para que la aplicación lo consuma. Paráte unos milisegunditos a ver si es que no viene otro atrás. A ver si nos ahorramos a enviar nada más un segmento de 40 bytes sin data. Imaginando que yo no tengo nada para decirle de regreso al otro. De tal manera de que yo pueda acumular más espacio de secuencia que me viene ahorrándome "hacks" de regreso. Ese concepto es simple de entender. Ese es el concepto de "delay hacks". Pero no solo me permite eso, demorar el "hack" y no ser tan "talk". Cuando digo "talk" se entiende, ¿no? "Talk" de trastorno obsesivo compulsivo. Que sería el TCP acá, así, obsesivamente, decir "hack, hack, hack, apenas te leo". "Momente, tranqui, pará, pará, pará". Te llegó este segmento. Vamos a este otro dibujo. Te llegó este segmento, ¿no? Normalmente vos tendrías que "hackar" pero vos te tomás un "tiempin". Ese tiempo es para... Tiene dos razones de ser. Una es que te lleguen más segmentos, ahorrarte "hacks" de regreso. Pero hay otra razón interesante que se llama "pigbacking". "Pigbacking" es algo así, más o menos, como... - "Hacko koich". - "Hacko koich", ¿sabes tú? Gracias. Exactamente eso. ¿Qué será "pigbacking"? ¿Cómo se podría aplicar acá "pigbacking"? A Pateco. Si yo me demoro en enviar el "hack", ¿quién puede estar interesado en responder algo a lo que le acaban de decir? Digo, yo estoy en el lado B, he recibido data del lado A. Se lo estoy subiendo a la aplicación. Si las cosas se dan más o menos rápido y la aplicación está despiertita, bien puede ser que la aplicación consuma esta data y tenga algo para responder. A nivel de protocolo de aplicación. HTTP, ustedes saben que funciona con el... Después se establece la conexión, ¿qué hace el cliente en HTTP? Protocolo de aplicación, altura de aplicación. ¿Qué escribe como HTTP? Miren, se lo estoy dibujando con las letritas. Hace un... - Un "get". - Un "get". Espacio, barra. Sí, o barra lo que fuera, barra index HTML. ¿Y qué hace en consecuencia el HTTP server? Si yo le hago un... conecto, "syncynac hack", yo, al lado del cliente, hago un "get" barra index HTML, ¿qué va a hacer el server? Claro, tiene que decirle que le llegó el "get" a un "hack" del "get". Sí, sí, eso haría TCP. Pero la aplicación, server, la aplicación, ¿qué hace en consecuencia? Responde con la página que está pidiendo. Bien, perfecto. ¿Qué también me dirá? ¿Significa qué? ¿Lo que entra por acá? El lado B... A ver, pará. Vamos a hacer mejor. Sube por acá, la aplicación procesa y tiene algo para responder quizás. ¿Qué pasará si yo demoro el "hack"? Entonces, recuerden, el "hack" no es un paquete aparte, sino que es una sobrecarga misma de la cabecera de TCP. Yo en vez de responderle un "hack" vacío, ¿qué le voy a poder responder? No solo te "hackeo" que te recibí bien, sino además... El primer tramo de información. Claro, de data, de data posta. Entonces, fíjense. Yo, lado receptor de TCP, al no ser un "toc", "hackeando" ahí como loco, esperando un poquitito, le doy la chance a la aplicación de que lea la data, la consuma, escriba su buffer de transmisión y cuando yo tengo que construir el "hack" a todo ese espacio, en realidad no solo le envío el "hack" y le digo, te "hackeo" a lo que me escribiste, sino que además te estoy enviando la respuesta, "piggybacking". Sí, a cocho del "hack" va la respuesta de data posta, ¿no? Es decir, cargadito el paquete en vez de ser 40. Ese procesamiento se tiene que dar más rápido que el "timeout". Ah, bien. Porque si no, nos rompe todo. ¿Cuál es el peligro de eso? Me encantó. Es peligroso. Si tardás mucho tiempo en procesar la información, o esperas demasiado para el "piggybacking". ¿Cuál es el más tiempo que tenemos que comparar? ¿Cuáles son los órdenes de magnitud que tenemos que comparar? ¿El "roundtrip time"? ¿Contra? El "roundtrip" está muy bien, ¿contra? A ver, si RTT es 100 milisegundos, y yo tardo, disculpen, tengo algo atravesado. Y yo tardo 200 milisegundos en procesarlo, ¿será negocio? Esperar. Dependiendo del "timeout". Ahí está. Pero por eso, si es 100 milisegundos, el otro debe estar estimando un "timeout" en 125, 150. Me digo que no es negocio esperar, porque justamente, exactamente lo que acaban de decir. Si yo espero demasiado, en vez de hacer "the talk", me convierto en un vago TCP receptor, lo que va a ocurrir es que el pobre otro, a pesar de que anduvo todo bien, va a decir, "no, no me llegó nunca, acta de mouse". Ventana a un PMTU, ventana de congestión. Como siempre, toda ingeniería, como bien sabremos, insistimos, es un compromiso. Entonces, ahí hay "timings" involucrados. Yo, como laboreceptor, puedo darle tiempo a la aplicación a que responda para que haga "piggybacking", si ese tiempo es fundamentalmente menor, el tiempo de procesamiento comparado con el RTT, que tengo en control del otro lado. Digamos, yo, por decir, si tengo un RTT de 100 milisegundos, y bueno, aplicación, te doy un milisegundo para que responda. Dos, cinco milisegundos. Pero no te voy a dar 200 milisegundos. Porque este "hack" quema, me quema en los dedos. Porque el otro lado, si no lo recibe pronto, va a creer que ha habido "hack timeout". Entonces, ese es, de alguna manera, el compromiso. Ustedes lo ven acá, lo hemos puesto. Fíjense, permite "piggybacking", es lo que disminuye el tráfico, justamente porque acumulamos espacio para "hackear". Acá, y esta, nuevamente. Acá, esta sí es información recibida de una entidad alienígena o celestial, donde los que dicen la RFC dicen, "Muchachos, no más de 500 milisegundos, muchachos, no más de dos PMTU sin "hackear". Quiere decir que si yo leo uno, dos, al tercero, ya me obligo a dos. En realidad, cuando leí el segundo, ya, no más de dos PMTU. No, al tercero, yo ya me obligo a "hackearlo" y no hago todo este firulete de esperar para que la aplicación responda y qué sé yo. Esos números mágicos que ven ahí, 500 milisegundos, dos segmentos, vienen de la RFC y vienen estrictamente de campo. De ver cómo se comportaba el protocolo en campo, de estimar cuáles son las demoras que hay en la Internet en general y poner números de compromiso. Bien. ¿Cuál es el RTT real? -Ese número, profe, perdón, ¿se actualiza? -Ah, buena pregunta. No sabría responderte, debería fijarme, pero sería interesante. Todo se configura, por cierto. Puede que la RFC no lo actualice, tampoco es taxativo, pero si ustedes agarran un... Voy a presentar otro plantado, esto lo pueden ver si ustedes quisieran en sus instancias en la cloud. Ahí tenemos un... ¿Se ve ahí el shell mío? -Sí. -Lo voy a aumentar un poquito. Bien, Pablo. A ver si lo puedo aumentar con este pod. Bueno, no importa. Whatever lo que quieras. Acá hay un... Bien. Vamos a proceder a probar este... Fine. Yo voy a... Fine. (HABLAN A LA VEZ) ¿Recuerdan dónde estaban los PROC y PCP? Digo, que siempre me... -PROC SISNET... -Ah, gracias. Exacto. PROC SISNET... Fíjense, tiene algunas configurabilidades. -Se ve re pequeño, Juan. -Ah, ¿se ve re pequeño? -Dale un par de control más. No aguanta. -No aguanta. Bueno, ahí está. Option más. ¿Qué es eso de control? Eso de control es para gente pobre. Nosotros usamos... -Después tengo para contarte una... Un... ¿Cómo se llama? Un desvarío que hice este fin de semana. -Bueno, dale. -De la última versión de Windows 10. -Ah, el LS. -Lo queremos a todos. -Miren, ¿qué les quería mostrar acá antes de que yo me desvaríe en el tema? Todo eso son los configurables que tiene un Linux moderno en cuanto a TCP. En particular... Y ahí se me han perdido algunos allá en la pantalla. A ver... Ah, es cierto, porque esta porquería encima... Que te mantiene la... Vamos de vuelta. Ahí me voy. No sé si acá hay alguno en particular con ese timer, habría que ver. Fíjense si es el "retrace 1", "retrace 2", son los "hack timeout". Estábamos viendo los "hack duplicados". No sé si es este "fhack" o este "dshack", no recuerdo, pero hay alguno de esos que es. Todo esto son... Si ustedes lo "catean", del verbo "catear", fíjense que son números que a veces es cantidad y en algunos casos representan segundos o milisegundos. Por ejemplo, no sé qué se dice. Este está hecho en milisegundos, 7200 milisegundos. Sí, dos horas, está bien. Y uno los cambia haciendo cosas tan complicadísimas como las siguientes. Tienen que ser "route", así que hacen un "sudo", hacen un "echo", por ejemplo, si quieren "TCP keep alive timeout" y le hacen "sudo t". Y ahora ya tienen un nuevo valor en 3600. Ahí "clic", le cambiaron al kernel este. Entonces, un poco respondiendo a tu pregunta, más allá de lo que diga la RFC, los sistemas operativos tienen mecanismos de configuración que te permiten optimizar eso de acuerdo al contexto en donde vos estás usando esto. Por ejemplo, recuerdo de mi tiempo en Google que todos estos parámetros estaban todos "recontra" retocados en los "datacenters" porque son "datacenters" con muy baja latencia, que tienen otro tipo de comportamiento. Estaban todos estos, estaban todos súper "recontra" tuneados, ajustados para un problema de laburo dentro de "datacenters" de alta capacidad de ancho de banda. Porque estos son "defaults" razonables para una máquina que está en la Internet. Como dice, en la Internet, interactuando con Internet. Para flujos dentro de un "datacenter" con "links" de alta velocidad y poca pérdida, esto se suele retocar. Era modo de mostrarles eso. Bien, dejo de presentar y volvemos. El del "slow start" dice uno. ¿Cómo? ¿Decís "slow start" ahí? Bien, buenísimo. Sí, lo encontré. Ah, genial, genial. Yo recuerdo, por ejemplo, por decir algo recuerdo en algún caso para sacar un poco más de jugo. Si ustedes ven, hay uno en particular que es "TCP/WMEM" y "TCP/RMEM". "Write Memory" y "Receive Memory" es el tamaño de buffer de recepción y buffer de transmisión. Por default. Así que hay mucho para jugar. Y recuerdo haber ajustado, en una situación en la cual queríamos sacar más "throughput" a una red, haber ajustado, aumentado los "TCP/WMEM" y "RMEM". Son gratis, ¿no? Le aumento el valor que tengan ahí, le pongo lo que sea y ya está. No sé por qué vienen tan bajos estos, desgraciado. Tiene tres valores igual. Ajá, claro. Son como tres ajustes. Fijate que "4096", "16384" y "4MB". Es decir, "4K", "16K" y "4MB". Ajá, bien. Así hacen un "MAN PROC". ¿Qué era "MAN PROC"? "MAN 5 PROC" creo que era. No me quiero ir al tema, pero me encanta tanto esto, por favor. Si hacen un "MAN 5 PROC" les describe eso y ahí pueden ver los detalles. Yo no me acuerdo ahora los detalles, pero una creo que es la ventana máxima, otra la de "Folder 16K" y la otra no me acuerdo. Recuerdo distintas situaciones de presión de memoria o algo así. Bueno, no me quiero ir al tema. Vamos. Volvemos al tema. Pero ahí, nada, se superentiende entonces que hay mucho configurable. Esta es la manera de hacerlo en Linux. Que no tiene por qué ser la manera, pero esta es la manera simple, orientada a archivos en que en general los sistemas UNIX aproximan este tipo de settings. Volvemos. Pregunta. ¿Cuál es el RTT? Yo me di este RTT. ¿Será estable este RTT? Depende de la congestión de la red. Bien, ok. Me di 100 milisegundos. Después será 101, 99, 100, o saltará mucho así. ¿Ustedes qué experiencia tienen con eso? ¿Qué tan estable? Sí, es bastante inestable. Inestable. Dependerá si tenés hermanos o hijos que torrentean mucho. Ya vamos a ver sobre los torrentes un momentito después. Dependerá si están Netflixeando, si estás solo a las 3, 4 de la mañana, que la red está hermosa, menos que estén todos tus vecinos jugando, no sé, algún juego que necesitan mucho antes de ir a banda. Es decir, ¿a qué voy con esto? ¿Qué trato de dibujar? Yo no controlo la situación de congestión de la red. Y es un valor muy inestable. ¿Qué mecanismo, recurso matemático, puedo usar para hacer smoothing? No una smooth de frutilla, sino smooth de un valor que es muy inestable. ¿Conocen ustedes algún tipo de smootheador? Un promedio. ¿Cómo se implementa ese promedio? Bien, un promedio. Primera implementación, naive, sería... Bueno, yo promedio todo lo que me di hasta ahora. Voy sampleando, obviamente, con cada interacción con el lado remoto, más allá de que esto fuese sin SYNAC, acá va a haber mucho data, en ambos sentidos. Por lo tanto, voy a tener muchas verticalidades acá, RTTs, para ir sampleando. He sampleado 100, 110, 95, 150, 170. Una primera implementación naive sería, memorizo todos los RTTs, me salgo la pantalla a propósito, todos los RTTs, esta conexión que lleva días y días, y los voy promediando para calcular el RTT actual. Esa implementación tiene algún problemín, ¿no? Necesitas mucha memoria. Memoria infinita en principio, o tan infinita como es orden N, tan infinita con cantidad de paquetes hayan. Está bien la idea del promedio, pero ese no es el mejor algoritmo para mantener un promedio. ¿Qué otra manera se le ocurre que podríamos hacer un promedio? El último valor más el nuevo dividido por 2, y ese se asigna como el último valor. El último valor más el nuevo dividido por 2. Ajá, y lo vas acumulando. Quiere decir que, vamos a ver si me sale, hasta ahora las matemáticas no son mi... Me encanta la matemática, me hizo bueno. Pero hasta ahora, vamos a ver si me sale con una... Voy a volver a una ventana. No me acuerdo si BC permitía... Déjeme probar una cosita. ¡Oh, sí! ¡Bien! Entonces, vamos a hacer que el promedio sea... Arrancamos con el primer valor, 100 milisegundos. Hacemos que el sampleo, el nuevo sample, sea 150. Un momento. Que igual a 100. Sample igual a 150. Y hacemos que... ¿Vos cuál era tu sugerencia? P igual a P más S dividido. Listo. Ese valor va a ser ahora... 125. Bien. ¿Qué pasa si ahora tengo un sampleo? No hace falta... Imagínense, no sé, 95. 110. ¿Cómo lo ven ustedes? ¿Va oscilando mucho, poco, el algoritmo que propuso su compañero? Imagínense que vuelvo a samplear ahora 140, por ejemplo. Vamos a hacer una cosa, vamos a hacer que me lo muestre con cada... Y oscila bastante. Y oscila mucho. Está, ojo, está muy buena la idea, pero fíjense cómo oscila. Va de 132 a 106, con algo que sabemos, que el R(t) es súper variable. ¿Cómo podríamos hacer que este P más S dividido por 2, que está muy buena la idea, que en realidad si lo pensamos a 0.5 de P a 0.5 de S, cierto? P más S dividido por 2. Uh, prof, se jugó con la matemática, pero sería así básicamente, ¿cierto? Es lo mismo que P más S sobre 2. Sí. ¿Coincide? Bien. ¿Cómo podríamos hacer para que sea más estable esto? ¿A cuál de los dos factores le daríamos más peso? Al viejo. A la memoria, al que va corriendo, al P, al promedio, movil, moving average. Si usan cripto, ustedes ya conocen el moving average. No me hagan trampa, el MACD lo han visto ahí en Binance, todo, así que no se me hagan acá los inocentes que no han visto un moving average nunca. ¿Cómo modificaría estos factores? 70-25, por ejemplo. Ah, now we're talking. Ah, casi we're talking. Tenemos un problema en Houston, we have a problem. 70-25. ¿Qué va a ocurrir? Me va a ir al piso. ¿Qué debería hacer? ¿70 cuánto? 75. O sea, me falta el... Ok, te quedaste corto. Bien, ok. ¿Qué pasa ahora? Si está, fíjense, el 99 que está corriendo le pongo un 140. Y bueno, fíjense que a medida que le voy poniendo, fíjense que interesante cómo va como de a poquito aproximándome, no lo move y de 140 se va como aproximando. Después de muchas pruebas, si ahora se mejoró la red y baja a 100, se va a ir de a poquito, plin, plin, plin, plin, plin. Como algo que sea más duro todavía. Súper duro. ¿Cuánto le pongo a cada factor? 99. Ah, bueno, está bien. Eso es súper, súper, súper. Está bien. Vamos a hacerlo superín. Ahora, algo así de 140, fíjense que tarda en llegar 140, tarda en moverse. Obviamente, como estaban sugiriendo recién, si le ponemos un 99 y .01 va a ser durísimo de moverse. Fíjense, está ahí. Bien, en esa situación de compromiso, nuevamente, en una sesión espiritista, a los implementadores de TCP les llegó la información de que el mejor era 0.8. En esa... Esperen que vuelvo a presentar porque yo estoy... Volvía la diapo. Nuevamente, entonces a... Magia ocurre, magia ocurre, magia ocurre, magia ocurre... A los implementadores de TCP les llegó la señal alienígena o extradimensional de que el número es 0.8. Obviamente estoy haciendo algo ridículo de eso, sencillamente con pruebas y de ver este comportamiento y de ver la... El jitter, jitter, es la palabra correcta para esta inestabilidad de la latencia, o al menos en este caso la RTT, 0.8 se encontró como un buen compromiso para hacer exactamente ese cálculo que hacíamos recién. Fíjense que en ese cálculo no tengo que almacenar más que el valor actual de la RTT. Y yo lo voy retroalimentando con la próxima muestra, pero no tengo que almacenar toda una historia, ni siquiera dos o tres. El RTT actual y yo le meto un 80% del actual y un 20% del nuevo sample, y lo vuelvo a almacenar. Y así mantengo un moving average. Y con eso trato de suavizar estos coletazos que puede tener. Act time out. ¿A cuánto lo hacemos igual? ¿A exactamente el RTT que tenemos? No, más alto. ¿Cuánto más alto? No vale leer la pizarra. Un 20%. Ah, bien. ¿Qué pasa si lo hacemos igual? ¿Cuál es el riesgo? Que cualquier problemilla que haga automáticamente alarga el time out. Bien, perfecto. Es demasiado riesgoso ponerlo justo. Tomémoslo, yo no recuerdo, nosotros en los diápagos hemos puesto entre 1 y 2, pero está bien, creo que estaba en el orden del 25% más arriba. Depende, obviamente, la red también es configurable. Quiero que me describan cuál es el problema de hacerlo bastante alto. Imagínense que fuera 10 veces el RTT. Está mal, obviamente, me hace ruido en la cabeza, está mal, pero... ¿Cómo va a afectar el comportamiento de TCP que me recontrafume el act time out en 10 veces el RTT? Recuerden, nosotros nos gusta explorar, para entender un valor razonable, nosotros exploramos los extremos. El extremo que tocamos recién es que fuera igual al RTT y con el jitter de latencia es demasiado peligroso porque el otro puede enseguida interpretar, mejor yo puedo interpretarlo como un act time out, obviamente porque estoy demasiado histérico con el act time out igual al RTT. Un extremo. El otro extremo, 10 veces el RTT. Listo, ponle por 10 de cacho y vamos para adelante. ¿Cuál...? La red está infrautilizada. Easy, tranqui, tranqui, tranqui. Entendamos el problema y respondamos bien. ¿Cuándo yo reacciono contra un act time out? Casi que me estoy respondiendo. Cuando pasa mucho tiempo y nada más haya una QC de recibo. Quiere decir que el peligro de hacerlo es muy grande. Si la red está bien, no pasa nada, loco. Si el act time out es act time out. Por lo tanto, si no tengo act time out, no hay act time out. Así que le puedo poner un valor infinito y ya está. ¿Por qué nunca hay act time out? Porque todo anda bien. Sabemos que esta es una situación unicorniana tipo Rainbow, que no es así. Pero en principio lo importante de entender es que el valor alto de act time out me modifica mi tiempo de reacción y retransmisión. Y retransmisión es cuando algo falló. Entonces es menos, como decir, tiene menos impacto hacerlo más grande, alejarse del RTT que acercarse al RTT. Porque al dejar el RTT, hacer el act time out sustancialmente más grande que el RTT, el único impacto es mi tiempo de reacción a retransmisión. Porque es justamente frente a act time out. Y es muchísimo más riesgoso acercarlo al RTT. Por eso que está entre 1 y 2. No me acuerdo, eso debe estar sacado de algún RFC, no me acuerdo cuál es el valor. Recién decimos 25%, pero honestamente no lo recuerdo. Bien, ¿se entendió esto? Son cosas súper interesantes de ver cómo es el juego, ¿no? Hay de tiempos. Fast retransmit. Fast retransmit lo vimos ya de una manera implícita. Y básicamente es, me siento, I'm feeling lucky o I'm not feeling lucky. Con el 3. Si yo tengo act duplicados, ese mismo senador que tenemos ahí. ¿Cómo sería mi comportamiento? I'm feeling lucky. Me siento afortunado. O estoy optimista hoy. ¿Y si yo hago act duplicados? Suponer que los otros sí le llegaron. Exacto. Y solamente retransmitir el 3. Ahí. Rezando los dedos, I'm feeling lucky. Entonces, eso se llama, básicamente, perdón, me confundí. Este es el fast recovery, no el fast retransmit. El fast recovery es solamente envío del segmento consecutivo, ahí sería el 3, de toda esa secuencia de act duplicados. Y de paso, infló la ventana de congestión momentáneamente para acomodarme, es como para tratar de recuperarme rápido de la situación de act duplicados. Ese es el fast recovery. Y el fast retransmit es, en realidad, el siguiente. Que también se da, era mayor o igual que decía, si hay más de 3 DUCs. A ver acá, ustedes son, nuevamente, recuerden que no vemos el universo, vemos solamente nuestro lado. Y hemos transmitido 1, 2, 3, 4, 5, 6 y recibimos. acá 2K, tac, tac, tac, tac, tac. Y el 3 hay que retransmitirlo. Casi que seguro. Ahora, yo soy TCP. ¿Cuándo retransmite un TCP, señorcito? ¿Cuándo retransmite un TCP? ¿Cuáles son las reglas que he aprendido de retransmisión de TCP? Crillos. Cuando me llegue a 1CK repetido. Ah, ah, ah, error, no. ¿Qué es lo que hemos aprendido hasta ahora? ¿Cuándo retransmite TCP con lo que hemos aprendido hasta ahora? ¿Cuándo retransmite TCP con lo que hemos aprendido hasta ahora? ¿Cuándo retransmite TCP con lo que hemos aprendido hasta ahora? Este "sequence number" me va a ir expresando cuánto voy avanzando yo en el espacio de secuencia. Justamente es este que está acá. O mejor dicho, acá creo que tenía uno que había puesto mejor. Este "sequence number" representa de mi lado de transmisión cuánto estoy en el espacio de secuencia. Este segmento que te envío ahora, ¿Cuál es el "offset" de su arranque de espacio de secuencia? Más el tamaño, esto va a ser el espacio de secuencia que te estoy enviando. Es decir, hay que recordar que este "TCP" lo que empuja es espacio de secuencia. Acá está empujando el espacio entre un "k" y dos "k", entre dos "k" y tres "k" con este segmento. Y entonces, por ejemplo, si mostramos este, el complicado de este tres que se perdió, en el "sequence number" acá diría tres mil, perdón, dos mil, dos "k". Porque estamos acá. Y en su tamaño dirá lo que tenga como tamaño, con lo cual el otro sabe qué posición ocupa. Porque como bien sabemos, la red IP no te garantiza entrega ordenada. Por lo tanto, estos seis que fueron pueden llegar en cualquier orden y el otro lado tiene que poder reposicionarlos. Entonces, huele igual a fragmentación, pero es muy diferente a fragmentación, porque esta es la capa de transporte, la que está peleando por cada segmento. Y que mantiene timers por cada segmento. Y si tienen que retransmitir, retransmite cada segmento, a diferencia de la fragmentación, que como vimos, un fragmentito perdido, perdimos todo el atagrama. Acá se pierde un segmento y yo, TCP transmisor, sé que es ese segmento. Todo lo que acabamos de ver. Soy optimista, retransmito el tres nada más, espero que me llegue el "hack", todo eso por cada segmento de espacio de secuencia. Entonces, hacia secuencia de empuje, es este, "acknowledgement number", ¿qué será? Si este tiene la dimensión de 32 bits, ¿qué será el "acknowledgement number"? Para decir la posición, como habíamos dicho, 2K+1. Ajá, exacto, lo que yo le hackeo, es mi personalidad receptora, ¿no? Mi personalidad transmisora dice "sequence number", mi personalidad receptora dice "y de paso", te voy hackeando a este. Pregunta, es opcional, ¿no? Yo lo puedo ahí omitir. Juan, ¿me esperás un segundito que voy a bootear mi máquina y vuelvo? Porque quiero estar al final, mostrar una cosita, ¿me esperás? ¿Pero puedo seguir con esto? Sí, sí, sí. Ah, ok, seguí, por supuesto. No, no, no, pero digo, voy a reiniciar esta cagada. Ah, sí, sí, sí, no corto, no corto antes, si acá tengo nada más que unos 40 minutos más. Mentira, mentira, debo tener 10, 15. Sí, sí, te esperamos. Bien, entonces, "sequence number" es mi gorrito transmisor y "acknowledgement number" es mi gorrito receptor donde te hackeo. Fíjense que algo interesante es que el "ack" viaja siempre. ¿Cuál es el único, el único segmento de una conexión que no tiene "ack"? El "syn", el "syn". El "syn". Todos los otros tienen "ack". Siempre tengo algo para hackear, aunque sea lo mismo. Siempre tengo algo para hackear. Será repetido o no, de acuerdo a si el otro sabe que me empujó data o no. Pero si el otro está quieto, no te transmito nada porque está recibiendo. Yo soy el lado B, estoy "del", "recibir", "delay", no tengo nada del protocolo de aplicación, no tiene nada para responder. Estoy quieto, no son "acks" duplicados los que recibo, porque sencillamente el otro lado me está hackeando lo último que yo le dije. Como yo no estoy transmitiendo nada más, ok, sí, es el mismo "ack", pero yo no he empujado espacio de secuencia. Entonces no es que empuje espacio de secuencia y me quedó pegado el "ack" a un espacio de secuencia que no se empujó. Sencillamente está viniendo el mismo valor porque yo no tengo nada nuevo para transmitir en mi sentido de transmisor, de B hacia A. ¿Eso sería cuando termine de transmitir el último segmento, digamos? No, no, no, ¿por qué? Hacer el último segmento. Bien, puede ser un protocolo, va, viene, va, viene, va, viene. No pensemos solo HTTP, de "get/", no. Pensemos una comunicación, por ejemplo, una comunicación como esta, más allá de que esté usando UDP por otras cuestiones que vamos a aprender. Pero si es HTTP, va, viene, va, viene, es permanente, no, viaja, se... Viaja, se... En los dos sentidos hay espacio de secuencia empujado, en los dos sentidos hay espacio de secuencia "acknowledgeado", no. Y cada paquete va tratando de empujar y hacer "ack" de lo que ha ido recibiendo uno de otro lado. Ya vamos a ver qué ocurre en el fin de conexión. Ya vamos a tener oportunidad porque es también interesante. Vemos rapidito estos... Checksum, ¿qué será el checksum? ¿Para qué estará? Calcular la integridad. Bien, de la cabecera nada más, igual que IP, ¿no? De todos, creo. De todos. Acá, bien. Ok, IP se hizo el "sota" y dijo "no, yo te garantizo mi cabecera", pero bueno, IP justamente no garantiza contenido, pero papi, vos sos TCP, vos me estás garantizando que llegas sin error, entonces ese checksum protege todo el contenido, toda la data. ¿Sí? Entonces incluso protege la cabecera propia, arranca bien, viene la cabecera, termina en el último baile de datos, e incluso le agrega pedazos de la cabecera IP. También protege, es como muy generoso ese checksum del TCP. Como que arma una especie de paquete virtual, el mismo, toda la parte TCP, cabecera más payload de aplicación, y le pone también la IP, origen y destino, y sobre eso arma el checksum. Porque es muy histérico de asegurar no solo el contenido, sino que el origen y el destino sean los que se pretendían. ¿Eso es por la 5-dupla? Sí, más o menos, es una buena razón. La 5-dupla está presente y está chequeada y asegurada por TCP. Muy buena observación. Urgent pointer, estamos medio tarde para verlo. Sí, lo vemos, total, vamos a morder la clase que viene en cabecera. Pero un segundito, dejame. Windows, ¿es opcional la ventana? Es decir, ¿cuánto tengo yo de espacio de recepción disponible? Me pongo el gorrito del lado receptor, mido el tamaño de buffer de RX, y lo digo o no lo digo, ¿cierto? A veces sí, a veces no. Y si pones cero es que no tenés ventana, así que... No, pero si pongo cero es que no tengo ventana, que es muy distinto a no decir nada. Claro. Bien, si digo cero, es cero. No es whatever, no es none, es cero. Punto es, no es opcional tampoco. Fíjense, todos, en todas las interacciones, siempre, vieja siempre, cuando tengo yo TCP que reconstruir lo que sea, empujando secuencia de bytes, espacio de secuencia, o hackeando al otro, o ambas cosas juntas en uno solo, siempre digo, y de paso, por cierto, por el mismo precio, a ver cuando está nuestro buffer de recepción, está en 20k, la ventana es, Windows, escribo 20k y viaja a los 20k. Y en toda interacción, en toda, va el contenido de la ventana, porque eso le da mucha actualización al lado transmisor, de en qué estado de control de flujo está del otro lado. Cuán presionado está el buffer de recepción. Entonces directamente, no es opcional, va siempre. Y después hay algunos flags. En estos flags, como para que sepan, estos flags contienen el SYN, el ACK, y vamos a ver el FIN, que vendría a ser el primo del SYN, pero para terminar una conexión, y algún otro flag loco por ahí. Pero esto lo vamos a morder de vuelta. Lo importante que queríamos ver es cómo cerrar esta parte de TCP hoy con un intro de la cabecerra. ¿Alguna duda de esto? No, ninguna. Bien, ya tenemos la grabación. ¿Vas a hacer algo que quieras agregar a la grabación, Diego? ¿Lo que querías mostrar ahora? Déjalo así. ¿Bonus track? Dale. Así queda como bonus track de... Buenísimo. En realidad iba para distender. Dejo de presentar iPod, tomar mate. A ver. Tengo la garganta seca. Todo tuyo. Toda mi pantalla. Bueno, parece que voy a ir desplegando mis trucos. Pantalla, chicos. Compartir. Ahí está. A ver, ¿de cuándo es esto? Es un ratito. ¿Se ve ahí? Sí. Dale un cachito más. A ver. Vos me troleaste cuando estábamos en el fondo, ahora yo te troleo. Qué sudo, cómo le cambio el fondo. Este es mi Windows 10. Ocultar. Que viene con mi... Con mi compu. No, lo que les quería comentar, la verdad que hace rato que lo vengo siguiendo y me parece que Microsoft está encaminando bien, me parece. Concido. Ha hecho muchísimos aportes de Open y Container. Este es mi Windows 10. Lo primero que les quiero contar, y les voy a dejar después, si quieren la punta de este ovillo, tiren de este link para entenderlo. Se los voy a poner acá. Microsoft acaba de liberar, hace rato que viene trabajando en un sistema que se llama Windows Subsystem for Linux, que básicamente permite correr Linux adentro de Windows. Yo he seguido mis pasos. Lo que voy a abrir es, esto es un Ubuntu 20, pero es un Ubuntu de verdad este. Esto está corriendo un Ubuntu de verdad. Y diríamos que la última, esto es WSL2, es decir, es Windows Linux Subsystem 2. Si hacés, por ejemplo, un Ame-A, te muestra la versión kernel. No, te quiero mostrar esto, claro. La versión anterior era una transcodificación de comando. Esto es una máquina virtual con un kernel hecho por Microsoft para correr arriba de Hyper-V, que accede hasta la más baja capa, digamos. Eso es el firewall de este. La verdad que está muy bien ofuscado para el cliente final, pero esto es una máquina virtual entera. Yo estoy en otra máquina, no estoy en mi máquina acá. Esto es una máquina virtual entera. Yo pongo acá ipconfig. Este es mi Windows. El Windows tiene un IP, como ustedes la ven acá, 54. Y esto tiene una red que ha creado facilísticamente acá. Entonces, la primera, digamos, esto está hace rato. Es Windows Linux Subsystem. Esto es un Linux entero. Acá yo tengo mi BI. Tengo un Ubuntu. Apete get update. Instalo lo que quiero. Muy bien logrado. Esto funciona muy bien. Lo que está muy simpático y siempre ha sido un trastorno, y eso es un poco lo que les quiero mostrar y está ahí en el puntero, es hace menos de un mes Microsoft resolvió la manera de integrar aplicaciones gráficas. Todo el manejo de aplicaciones gráficas en Unix es una galleta. No es una galleta, es perfecto, pero entenderlo es difícil. Pero lo que yo les quiero mostrar es esto. Yo voy a abrir una Xterm. Primero mira la velocidad en la que abrió. Esto es una aplicación gráfica de mi Ubuntu. ¡Oh! Está suelta, boludo. ¡Qué bárbaro! ¿La ves? ¡Qué locura! Mirá. Claro, es un widget. Bueno, es un widget. Tiene un frame gráfico en el mismo... No, no, no, por eso. Y muy liviano, anda muy fuerte esto. ¡Qué bien! Le voy a mostrar... Justo iba a preguntar si se podía poner interfaz gráfica. Mirá esto. A ver si... Bueno, lo que acaba de lograr Microsoft es esto. Mirá, este es mi Open Office, pero está corriendo adentro de esa máquina virtual y está hallando... La verdad que es una galleta lo que han hecho. Es muy interesante. ¿Hacés Open File como te mapea tu File System? Está mi File System Linux. Mi File System Linux que está montado acá. Pero obviamente ellos han mapeado al /mntc. Ah, perfecto. /mntc está mi disco C de mi máquina Linux. ¿Y cómo es /mntc/usertiego? No, si quiero. Mi home es /home/ de Navarro porque es un UNIX. Pero si quiero ir a mi Windows, puedo entrar por ahí. Lo que quiero decirte es que esta es... New Text Document. ¿Cómo está hecho esto? Si lo ves, Juan, es un RDP contra una máquina. Ah, mirá. Y lo han resuelto todo por adentro los tipos. Tiene un nucleocito de RDP, entonces corriendo. Si vas a un PSAXX, verás ese RDP. Mirá, mirá. Esta es la solución. Está muy interesante esa nota que le acabo de pegar. No tiene desperdicio. Si les interesan los sistemas operativos y las cosas... Qué bien. Esto, para poder disfrutarlo, tienen que tocar su Windows. La verdad que no uso mucho el Windows. Me tomó un tiempo. Capaz que para ustedes es una pavada. Hay que tocar acá, poner el canal. Hay que suscribirse al Windows Insider. Windows Insider. Y es como que tenés que sintonizar el canal de desarrollo. Windows. Insider. Y te reinstala el operativo, en realidad. Insider. Acá está. Programa Windows Insider. Acá hay que agarrar y decir que querés el canal de desarrollo. Y ahí te aparece la actualización en el Windows Update. Y le pones... Necesitas la última versión de desarrollo, que es... Acá está la... Opción de avanzada. ¿Dónde es que se ve? Información de compilación. Es la 21... No sé cuánto. Farasa, sasa, fafa. Esto. No sé. Bueno, ahí explica el coso. Ahí está, la 21390. Y trae... Yo lo había hecho andar. Le había puesto un XServer y lo había hecho andar igual. Pero esto está muy bien resuelto. De hecho... Mirá. Mirá esto. Mate Session. Mirá qué galleta. Y es lo que hace jugar. Mirá cómo flotan. No sé si se va a alcanzar. A ver. Este es XFault, o me parece en el... ...le va a haber corrido como root. A ver. Sí, le ha corrido como root. Y ha quedado pegado. Mirá esto. ¿Lo ves? Sí. Claro. Sí, sí, sí. Te armó toda la sesión. Qué bueno. Transparentado. Es como un poco de... Es como un poco de... ¿Cómo se llama? Transparentado. Es como un frame transparente. Por eso. Pero esto es un RDP contra la máquina. ¿Entendés? Sí. Las ventanas están... Es como si le hubieran hecho un manejador de ventanas... ...que habla RDP contra... Claro, pero lo que es interesante es que no te marca todas las ventanas. Eso que las ventanas están libres flotando. Eso está súper bueno. Está muy bien. Lo de siempre. Tenés un escritorio y adentro, como lo tenemos en la Cloud, por ejemplo. Bueno, les recomiendo que lo prueben. Y les doy dos... Esto es lo último. Se llama WSLG. Es Open Source. Microsoft lo ha liberado Open Source esto. Está en GitHub el código. Está acá. Esto es Open Source. Lo que han hecho. Sí, están muy... Están muy, muy... ...sincronizados. Y les quiero mostrar dos cositas más. Para que lo tengan. Que está muy bien resuelto también. Yo tengo Docker, que ya lo vamos a ver, corriendo en mi máquina. Es decir que si yo hago acá... Docker... ...PS. Perdón. Ah, Docker para Windows, negro. Docker de Windows está corriendo. Sí, pero mirá esto. Este Docker de Windows está conectado por acá adentro con este Docker. Es el mismo Docker. Ah, le han exportado el socket de conexión y qué sé yo. Y en realidad... Está muy bien resuelto. Es decir que... Es más, si yo acá hago... Docker Run. Docker Images, para que ustedes lo vean. O haces un Docker Run - IT Alpine o algo así. Una cosilla de esas. Fíjate. Docker PS. Pronto. Está bien. Y este Docker... ...si ustedes lo miren... ...trae una cosa muy bonita, que es esta. ¿Tenés idea de quién costó el Docker D? Ahí en ese caso, sigue siendo el Docker de Windows. El Windows, es este. Y este Docker viene con un clastercito Kubernetes de regalos. Sí, bueno, esos son los Dockers nuevos en general, pero está bueno. Qué bueno, qué bueno. Así que ahí tenés KubeCTL, si quisieras, si lo apuntás bien. Y yo podría usar... Sí. Sí, es verdad. Si lo pudiera apuntar acá afuera. Y puedo... ...apuntar aquí. Y puedo... Bueno, han hecho una conexión... Si usar al... Creo que lo tengo. Visual Studio. Visual... No, no lo tengo acá. Visual Studio. No lo tengo. No, no lo tengo. Bueno, podés usar Visual Studio... ...y desarrollar en el Windows conectado a la máquina Linux. Bueno, este es un... Este es una segunda capa... Una tercera capa de Incepción, digamos. Están borrando los bordes, digamos, para que... Claro. La verdad que alguien no se sepa... Es decir... Esto es una máquina virtual entera y se puede convivir... Lo que hay atrás se llama WSL, acá. Y ustedes pueden tener varias distros. Yo tengo ahora puesto la Ubuntu 20, pero podría acá instalar otro Linux. Desde el Windows y tener varias distros Linux. Adentro de esto, corriendo como esto. Y a su vez, cada una de ellas, tener... Ambiente gráfico, digamos. Se les pega el teclado a veces, no es que está... Pero... Bueno, nada. Era mostrarles eso. Que ya dominamos Windows también. Sí, muy bueno. Ahora, también establece cuál es la inf... Cuál es el destino de la infra contenedizada. Dónde está lo que va a correr tu aplicación de producción. Ya está, ¿no? Sí. Sí, claro. No, pero muy bien, Che. Sí, muy bien. Muy bien. Hace más o menos dos años y medio, Microsoft hizo una contratación masiva de gente del mundo... Open Source, específicamente de gente de Docker, contenedización. Y acá se ven los frutos. Muy, muy, muy bueno. Así que, si alguno lo quiere probar y tiene... Bah. No le diría que alguien quiere probar. Esto es cultura general, muchachos. Pero ustedes deberían saber lo que... Es más, deberían hacer... Si tienen Windows, deberían hacer andar sus... Sus... Sus mininetes. Ahí, adentro. Ah, no, puta, no hice esa prueba. Puta, me quedé en paz. No, no tengo... Pensé que la demo era eso, prácticamente. No tengo... No, no, no, quería ver... No tengo... No tengo mi ceratina acá adentro. No, quería ver por ahí si me conectaba remoto, a ver si me desplayaba... No, pero yo te decía los mininetes directamente a autocontenido del mismo host, pero bueno... Ah, bueno, sí, acá sí lo hago. Sí, eso es obvio, pero estoy diciendo una viega. "Install mn" No, "mininet". "net" Y corres el editor, tiene que poner... Tenés razón. ...tu barra. Tenés termes y todo. Tenés razón. ¿Se entendió lo que vimos, muchachos? ¿Alguien entendió? ¿Qué está pasando? Sí, sí, se entendió. Sí, una locura me pareció. Muy bueno, muy bueno. Pará, entonces... Déjame ver, vos decís... Ni hablar que le... Te digo, ni hablar que le pase el trapo a esta porquería bonita que tengo acá frente a mí. El Docker para Mac apesta. Bueno, si me siguen en Twitter han visto que yo sistemáticamente estoy trasheando a Mac. Si hay algún goal que tengo en mi vida es que alguien pueda decirme gastarse más de 2.000 dólares en esta cosa bonita, cara y no usable para containers. ¿Y por qué usa Mac, profe? Por la compañía para la que laburo, una cuestión de policy. Porque le pueden instalar... Esta máquina está auditada por una cuestión de compliance. Nuestra compañía obviamente tiene clientes y para poder hacer compliance, como nosotros laburamos remoto, esta máquina en la que yo trabajo tiene que estar monitorizada por cuestión de seguridad. Y esa monitorización la tienen implementada... Han como que normalizado la plataforma de trabajo de los empleados en Mac. Estamos empujando un poquitito para ver si entra Linux ahí. Nuestro CTO, Diego, es un ex Microsoft y tiene el corazoncito ahí, así que estoy juntando básicamente jurisprudencia para mostrar lo pedorro que es el entorno de Docker en Mac. Para ver si nos darían la puertita de investigar... Si no, pedile, si es hombre Mac, es hombre Windows, pedile que te traiga una Sarf Ix. Una Sarf Ix, una que tiene procesadores MIPS. Tiene procesador... Los otros... Arch. Lo que pasa es que corre dos pavadas de Windows, no se le podía parar a Linux. Tranqui, estoy de poquito... Creo que voy a tener éxito en quizás... Ahí estamos, mirá papá. Bien. Ah, mirá que belleza. Belleza, belleza. De toque. Sí, obvio. Y ahí podías abrir una Kisterma allá adentro, ¿no? Sí. Bueno, cuando lo corras, lo mandás a correr. Ah. Run. Ah, no, lo pasé como root. Igual, esto anda muy fuerte, se ven livianitas las cosas. Bueno, mi máquina es un i7, pero... Bueno, no tienen excusa, muchachos, para estudiar. Miren, si quieren quedarse adentro de sus Windows... Está todo bien con el Windows. Muy buena noche. A ver, msudo.mn. Database connection file. Ah, está usando vSwitch. Servi. Bueno, a ver qué ponés. Son controladores borde de la cosa. No, pero puede ser por ahí que el networking tenga algunos... No, es que este Ubuntu es como un container, no tiene... Mirá. Sí, claro. Ah, mirá, PSA. Un init, un init, nada, no hay idea. Un init, mirá. Por acá habla con el socket. Ajá, ahí se lo lleva al host. Bueno. A darle una muradita, si quieren. Acá se los pegué en el Slack, el link a donde lo pueden ver. Y nada más, eso. No les robamos más tiempo. Muy bueno, Diego, gracias, loco. Muy bien. Bueno, mucho gusto. Paro la grabación. Un perk.